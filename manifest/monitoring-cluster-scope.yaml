##Prometheus Configuration
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  labels:
    app: prometheus
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
  labels:
    app: prometheus
rules:
  - apiGroups: [""] # "" indicates the core API group
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
      - namespace
      - deployments
    verbs:
      - get
      - list
      - watch
  # - nonResourceURLs:
  #     - /metrics
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus

  labels:
    app: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-alertrules
data:
  alert.rules: |
    groups:
    - name: PM2 Alert
      rules:
        # Alert for high error rate in the Sock Shop.
        - alert: HighErrorRate
          expr: rate(request_duration_seconds_count{status_code="500"}[5m]) > 1
          for: 5m
          labels:
            severity: "slack"
          annotations:
            summary: "High HTTP 500 error rates"
            description: "Rate of HTTP 500 errors per 5 minutes: {{ $value }}"
    - name: node-exporter.rules
      rules:
      - expr: |
          count without (cpu) (
            count without (mode) (
              node_cpu_seconds_total{job="node-exporter"}
            )
          )
        record: instance:node_num_cpu:sum
      - expr: |
          1 - avg without (cpu, mode) (
            rate(node_cpu_seconds_total{job="node-exporter", mode="idle"}[1m])
          )
        record: instance:node_cpu_utilisation:rate1m
      - expr: |
          (
            node_load1{job="node-exporter"}
          /
            instance:node_num_cpu:sum{job="node-exporter"}
          )
        record: instance:node_load1_per_cpu:ratio
      - expr: |
          1 - (
            node_memory_MemAvailable_bytes{job="node-exporter"}
          /
            node_memory_MemTotal_bytes{job="node-exporter"}
          )
        record: instance:node_memory_utilisation:ratio
      - expr: |
          rate(node_vmstat_pgmajfault{job="node-exporter"}[1m])
        record: instance:node_vmstat_pgmajfault:rate1m
      - expr: |
          rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
        record: instance_device:node_disk_io_time_seconds:rate1m
      - expr: |
          rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
        record: instance_device:node_disk_io_time_weighted_seconds:rate1m
      - expr: |
          sum without (device) (
            rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[1m])
          )
        record: instance:node_network_receive_bytes_excluding_lo:rate1m
      - expr: |
          sum without (device) (
            rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[1m])
          )
        record: instance:node_network_transmit_bytes_excluding_lo:rate1m
      - expr: |
          sum without (device) (
            rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[1m])
          )
        record: instance:node_network_receive_drop_excluding_lo:rate1m
      - expr: |
          sum without (device) (
            rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[1m])
          )
        record: instance:node_network_transmit_drop_excluding_lo:rate1m
    - name: kube-apiserver.rules
      rules:
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1d]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[1d])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[1d])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[1d]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
        labels:
          verb: read
        record: apiserver_request:burnrate1d
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1h]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[1h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[1h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[1h]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
        labels:
          verb: read
        record: apiserver_request:burnrate1h
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[2h]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[2h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[2h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[2h]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
        labels:
          verb: read
        record: apiserver_request:burnrate2h
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[30m]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[30m])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[30m])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[30m]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
        labels:
          verb: read
        record: apiserver_request:burnrate30m
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[3d]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[3d])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[3d])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[3d]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
        labels:
          verb: read
        record: apiserver_request:burnrate3d
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[5m]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[5m])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[5m])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[5m]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
        labels:
          verb: read
        record: apiserver_request:burnrate5m
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[6h]))
              -
              (
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[6h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[6h])) +
                sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[6h]))
              )
            )
            +
            # errors
            sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
        labels:
          verb: read
        record: apiserver_request:burnrate6h
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1d]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
        labels:
          verb: write
        record: apiserver_request:burnrate1d
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1h]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
        labels:
          verb: write
        record: apiserver_request:burnrate1h
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[2h]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
        labels:
          verb: write
        record: apiserver_request:burnrate2h
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[30m]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
        labels:
          verb: write
        record: apiserver_request:burnrate30m
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[3d]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
        labels:
          verb: write
        record: apiserver_request:burnrate3d
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[5m]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
        labels:
          verb: write
        record: apiserver_request:burnrate5m
      - expr: |
          (
            (
              # too slow
              sum(rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
              -
              sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[6h]))
            )
            +
            sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
          )
          /
          sum(rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
        labels:
          verb: write
        record: apiserver_request:burnrate6h
      - expr: |
          sum by (code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
        labels:
          verb: read
        record: code_resource:apiserver_request_total:rate5m
      - expr: |
          sum by (code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
        labels:
          verb: write
        record: code_resource:apiserver_request_total:rate5m
      - expr: |
          histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET"}[5m]))) > 0
        labels:
          quantile: "0.99"
          verb: read
        record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))) > 0
        labels:
          quantile: "0.99"
          verb: write
        record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      - expr: |
          sum(rate(apiserver_request_duration_seconds_sum{subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod)
          /
          sum(rate(apiserver_request_duration_seconds_count{subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod)
        record: cluster:apiserver_request_duration_seconds:mean5m
      - expr: |
          histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
        labels:
          quantile: "0.99"
        record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
        labels:
          quantile: "0.9"
        record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
        labels:
          quantile: "0.5"
        record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - interval: 3m
      name: kube-apiserver-availability.rules
      rules:
      - expr: |
          1 - (
            (
              # write too slow
              sum(increase(apiserver_request_duration_seconds_count{verb=~"POST|PUT|PATCH|DELETE"}[30d]))
              -
              sum(increase(apiserver_request_duration_seconds_bucket{verb=~"POST|PUT|PATCH|DELETE",le="1"}[30d]))
            ) +
            (
              # read too slow
              sum(increase(apiserver_request_duration_seconds_count{verb=~"LIST|GET"}[30d]))
              -
              (
                sum(increase(apiserver_request_duration_seconds_bucket{verb=~"LIST|GET",scope=~"resource|",le="0.1"}[30d])) +
                sum(increase(apiserver_request_duration_seconds_bucket{verb=~"LIST|GET",scope="namespace",le="0.5"}[30d])) +
                sum(increase(apiserver_request_duration_seconds_bucket{verb=~"LIST|GET",scope="cluster",le="5"}[30d]))
              )
            ) +
            # errors
            sum(code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
          )
          /
          sum(code:apiserver_request_total:increase30d)
        labels:
          verb: all
        record: apiserver_request:availability30d
      - expr: |
          1 - (
            sum(increase(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[30d]))
            -
            (
              # too slow
              sum(increase(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="0.1"}[30d])) +
              sum(increase(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="0.5"}[30d])) +
              sum(increase(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="5"}[30d]))
            )
            +
            # errors
            sum(code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
          )
          /
          sum(code:apiserver_request_total:increase30d{verb="read"})
        labels:
          verb: read
        record: apiserver_request:availability30d
      - expr: |
          1 - (
            (
              # too slow
              sum(increase(apiserver_request_duration_seconds_count{verb=~"POST|PUT|PATCH|DELETE"}[30d]))
              -
              sum(increase(apiserver_request_duration_seconds_bucket{verb=~"POST|PUT|PATCH|DELETE",le="1"}[30d]))
            )
            +
            # errors
            sum(code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
          )
          /
          sum(code:apiserver_request_total:increase30d{verb="write"})
        labels:
          verb: write
        record: apiserver_request:availability30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="LIST",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="GET",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="POST",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PUT",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PATCH",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="DELETE",code=~"2.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="LIST",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="GET",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="POST",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PUT",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PATCH",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="DELETE",code=~"3.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="LIST",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="GET",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="POST",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PUT",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PATCH",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="DELETE",code=~"4.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="LIST",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="GET",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="POST",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PUT",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="PATCH",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code, verb) (increase(apiserver_request_total{job="apiserver",verb="DELETE",code=~"5.."}[30d]))
        record: code_verb:apiserver_request_total:increase30d
      - expr: |
          sum by (code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
        labels:
          verb: read
        record: code:apiserver_request_total:increase30d
      - expr: |
          sum by (code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
        labels:
          verb: write
        record: code:apiserver_request_total:increase30d
    - name: k8s.rules
      rules:
      - expr: |
          sum(rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[5m])) by (namespace)
        record: namespace:container_cpu_usage_seconds_total:sum_rate
      - expr: |
          sum by (cluster, namespace, pod, container) (
            rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[5m])
          ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
            1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
          )
        record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
      - expr: |
          container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
          * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
            max by(namespace, pod, node) (kube_pod_info{node!=""})
          )
        record: node_namespace_pod_container:container_memory_working_set_bytes
      - expr: |
          container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
          * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
            max by(namespace, pod, node) (kube_pod_info{node!=""})
          )
        record: node_namespace_pod_container:container_memory_rss
      - expr: |
          container_memory_cache{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
          * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
            max by(namespace, pod, node) (kube_pod_info{node!=""})
          )
        record: node_namespace_pod_container:container_memory_cache
      - expr: |
          container_memory_swap{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
          * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
            max by(namespace, pod, node) (kube_pod_info{node!=""})
          )
        record: node_namespace_pod_container:container_memory_swap
      - expr: |
          sum(container_memory_usage_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}) by (namespace)
        record: namespace:container_memory_usage_bytes:sum
      - expr: |
          sum by (namespace) (
              sum by (namespace, pod) (
                  max by (namespace, pod, container) (
                      kube_pod_container_resource_requests_memory_bytes{job="kube-state-metrics"}
                  ) * on(namespace, pod) group_left() max by (namespace, pod) (
                      kube_pod_status_phase{phase=~"Pending|Running"} == 1
                  )
              )
          )
        record: namespace:kube_pod_container_resource_requests_memory_bytes:sum
      - expr: |
          sum by (namespace) (
              sum by (namespace, pod) (
                  max by (namespace, pod, container) (
                      kube_pod_container_resource_requests_cpu_cores{job="kube-state-metrics"}
                  ) * on(namespace, pod) group_left() max by (namespace, pod) (
                    kube_pod_status_phase{phase=~"Pending|Running"} == 1
                  )
              )
          )
        record: namespace:kube_pod_container_resource_requests_cpu_cores:sum
      - expr: |
          max by (cluster, namespace, workload, pod) (
            label_replace(
              label_replace(
                kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
                "replicaset", "$1", "owner_name", "(.*)"
              ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
                1, max by (replicaset, namespace, owner_name) (
                  kube_replicaset_owner{job="kube-state-metrics"}
                )
              ),
              "workload", "$1", "owner_name", "(.*)"
            )
          )
        labels:
          workload_type: deployment
        record: mixin_pod_workload
      - expr: |
          max by (cluster, namespace, workload, pod) (
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          )
        labels:
          workload_type: daemonset
        record: mixin_pod_workload
      - expr: |
          max by (cluster, namespace, workload, pod) (
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          )
        labels:
          workload_type: statefulset
        record: mixin_pod_workload
    - name: kube-scheduler.rules
      rules:
      - expr: |
          histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.99"
        record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.99"
        record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.99"
        record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.9"
        record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.9"
        record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.9"
        record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.5"
        record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.5"
        record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
        labels:
          quantile: "0.5"
        record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - name: node.rules
      rules:
      - expr: |
          sum(min(kube_pod_info{node!=""}) by (cluster, node))
        record: ':kube_pod_info_node_count:'
      - expr: |
          topk by(namespace, pod) (1,
            max by (node, namespace, pod) (
              label_replace(kube_pod_info{job="kube-state-metrics",node!=""}, "pod", "$1", "pod", "(.*)")
          ))
        record: 'node_namespace_pod:kube_pod_info:'
      - expr: |
          count by (cluster, node) (sum by (node, cpu) (
            node_cpu_seconds_total{job="node-exporter"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          ))
        record: node:node_num_cpu:sum
      - expr: |
          sum(
            node_memory_MemAvailable_bytes{job="node-exporter"} or
            (
              node_memory_Buffers_bytes{job="node-exporter"} +
              node_memory_Cached_bytes{job="node-exporter"} +
              node_memory_MemFree_bytes{job="node-exporter"} +
              node_memory_Slab_bytes{job="node-exporter"}
            )
          ) by (cluster)
        record: :node_memory_MemAvailable_bytes:sum
    - name: kubelet.rules
      rules:
      - expr: |
          histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le) * on(instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
        labels:
          quantile: "0.99"
        record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le) * on(instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
        labels:
          quantile: "0.9"
        record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
      - expr: |
          histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le) * on(instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
        labels:
          quantile: "0.5"
        record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - name: kube-prometheus-node-recording.rules
      rules:
      - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[3m])) BY
          (instance)
        record: instance:node_cpu:rate:sum
      - expr: sum((node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}))
          BY (instance)
        record: instance:node_filesystem_usage:sum
      - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
        record: instance:node_network_receive_bytes:rate:sum
      - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
        record: instance:node_network_transmit_bytes:rate:sum
      - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m])) WITHOUT
          (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total)
          BY (instance, cpu)) BY (instance)
        record: instance:node_cpu:ratio
      - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m]))
        record: cluster:node_cpu:sum_rate5m
      - expr: cluster:node_cpu_seconds_total:rate5m / count(sum(node_cpu_seconds_total)
          BY (instance, cpu))
        record: cluster:node_cpu:ratio
    - name: kube-prometheus-general.rules
      rules:
      - expr: count without(instance, pod, node) (up == 1)
        record: count:up1
      - expr: count without(instance, pod, node) (up == 0)
        record: count:up0
    - name: kube-state-metrics
      rules:
      - alert: KubeStateMetricsListErrors
        annotations:
          message: kube-state-metrics is experiencing errors at an elevated rate in
            list operations. This is likely causing it to not be able to expose metrics
            about Kubernetes objects correctly or at all.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatemetricslisterrors
        expr: |
          (sum(rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m]))
            /
          sum(rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m])))
          > 0.01
        for: 15m
        labels:
          severity: critical
      - alert: KubeStateMetricsWatchErrors
        annotations:
          message: kube-state-metrics is experiencing errors at an elevated rate in
            watch operations. This is likely causing it to not be able to expose metrics
            about Kubernetes objects correctly or at all.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatemetricswatcherrors
        expr: |
          (sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m]))
            /
          sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m])))
          > 0.01
        for: 15m
        labels:
          severity: critical
    - name: node-exporter
      rules:
      - alert: NodeFilesystemSpaceFillingUp
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available space left and is filling
            up.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemspacefillingup
          summary: Filesystem is predicted to run out of space within the next 24 hours.
        expr: |
          (
            node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 40
          and
            predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 24*60*60) < 0
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: warning
      - alert: NodeFilesystemSpaceFillingUp
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available space left and is filling
            up fast.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemspacefillingup
          summary: Filesystem is predicted to run out of space within the next 4 hours.
        expr: |
          (
            node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 15
          and
            predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: critical
      - alert: NodeFilesystemAlmostOutOfSpace
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available space left.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutofspace
          summary: Filesystem has less than 5% space left.
        expr: |
          (
            node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 5
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: warning
      - alert: NodeFilesystemAlmostOutOfSpace
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available space left.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutofspace
          summary: Filesystem has less than 3% space left.
        expr: |
          (
            node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 3
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: critical
      - alert: NodeFilesystemFilesFillingUp
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available inodes left and is filling
            up.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemfilesfillingup
          summary: Filesystem is predicted to run out of inodes within the next 24 hours.
        expr: |
          (
            node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 40
          and
            predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h], 24*60*60) < 0
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: warning
      - alert: NodeFilesystemFilesFillingUp
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available inodes left and is filling
            up fast.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemfilesfillingup
          summary: Filesystem is predicted to run out of inodes within the next 4 hours.
        expr: |
          (
            node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 20
          and
            predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: critical
      - alert: NodeFilesystemAlmostOutOfFiles
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available inodes left.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutoffiles
          summary: Filesystem has less than 5% inodes left.
        expr: |
          (
            node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 5
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: warning
      - alert: NodeFilesystemAlmostOutOfFiles
        annotations:
          description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
            has only {{ printf "%.2f" $value }}% available inodes left.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutoffiles
          summary: Filesystem has less than 3% inodes left.
        expr: |
          (
            node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 3
          and
            node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
          )
        for: 1h
        labels:
          severity: critical
      - alert: NodeNetworkReceiveErrs
        annotations:
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
            {{ printf "%.0f" $value }} receive errors in the last two minutes.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworkreceiveerrs
          summary: Network interface is reporting many receive errors.
        expr: |
          increase(node_network_receive_errs_total[2m]) > 10
        for: 1h
        labels:
          severity: warning
      - alert: NodeNetworkTransmitErrs
        annotations:
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
            {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworktransmiterrs
          summary: Network interface is reporting many transmit errors.
        expr: |
          increase(node_network_transmit_errs_total[2m]) > 10
        for: 1h
        labels:
          severity: warning
      - alert: NodeHighNumberConntrackEntriesUsed
        annotations:
          description: '{{ $value | humanizePercentage }} of conntrack entries are used.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodehighnumberconntrackentriesused
          summary: Number of conntrack are getting close to the limit.
        expr: |
          (node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75
        labels:
          severity: warning
      - alert: NodeTextFileCollectorScrapeError
        annotations:
          description: Node Exporter text file collector failed to scrape.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodetextfilecollectorscrapeerror
          summary: Node Exporter text file collector failed to scrape.
        expr: |
          node_textfile_scrape_error{job="node-exporter"} == 1
        labels:
          severity: warning
      - alert: NodeClockSkewDetected
        annotations:
          message: Clock on {{ $labels.instance }} is out of sync by more than 300s.
            Ensure NTP is configured correctly on this host.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodeclockskewdetected
          summary: Clock skew detected.
        expr: |
          (
            node_timex_offset_seconds > 0.05
          and
            deriv(node_timex_offset_seconds[5m]) >= 0
          )
          or
          (
            node_timex_offset_seconds < -0.05
          and
            deriv(node_timex_offset_seconds[5m]) <= 0
          )
        for: 10m
        labels:
          severity: warning
      - alert: NodeClockNotSynchronising
        annotations:
          message: Clock on {{ $labels.instance }} is not synchronising. Ensure NTP
            is configured on this host.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodeclocknotsynchronising
          summary: Clock not synchronising.
        expr: |
          min_over_time(node_timex_sync_status[5m]) == 0
        for: 10m
        labels:
          severity: warning
    - name: kubernetes-apps
      rules:
      - alert: KubePodCrashLooping
        annotations:
          message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
            }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
        expr: |
          rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[5m]) * 60 * 5 > 0
        for: 15m
        labels:
          severity: warning
      - alert: KubePodNotReady
        annotations:
          message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready
            state for longer than 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
        expr: |
          sum by (namespace, pod) (
            max by(namespace, pod) (
              kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown"}
            ) * on(namespace, pod) group_left(owner_kind) topk by(namespace, pod) (
              1, max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})
            )
          ) > 0
        for: 15m
        labels:
          severity: warning
      - alert: KubeDeploymentGenerationMismatch
        annotations:
          message: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment
            }} does not match, this indicates that the Deployment has failed but has
            not been rolled back.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
        expr: |
          kube_deployment_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_deployment_metadata_generation{job="kube-state-metrics"}
        for: 15m
        labels:
          severity: warning
      - alert: KubeDeploymentReplicasMismatch
        annotations:
          message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not
            matched the expected number of replicas for longer than 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
        expr: |
          (
            kube_deployment_spec_replicas{job="kube-state-metrics"}
              !=
            kube_deployment_status_replicas_available{job="kube-state-metrics"}
          ) and (
            changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[5m])
              ==
            0
          )
        for: 15m
        labels:
          severity: warning
      - alert: KubeStatefulSetReplicasMismatch
        annotations:
          message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has
            not matched the expected number of replicas for longer than 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
        expr: |
          (
            kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
              !=
            kube_statefulset_status_replicas{job="kube-state-metrics"}
          ) and (
            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
              ==
            0
          )
        for: 15m
        labels:
          severity: warning
      - alert: KubeStatefulSetGenerationMismatch
        annotations:
          message: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset
            }} does not match, this indicates that the StatefulSet has failed but has
            not been rolled back.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
        expr: |
          kube_statefulset_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_statefulset_metadata_generation{job="kube-state-metrics"}
        for: 15m
        labels:
          severity: warning
      - alert: KubeStatefulSetUpdateNotRolledOut
        annotations:
          message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update
            has not been rolled out.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout
        expr: |
          (
            max without (revision) (
              kube_statefulset_status_current_revision{job="kube-state-metrics"}
                unless
              kube_statefulset_status_update_revision{job="kube-state-metrics"}
            )
              *
            (
              kube_statefulset_replicas{job="kube-state-metrics"}
                !=
              kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
            )
          )  and (
            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
              ==
            0
          )
        for: 15m
        labels:
          severity: warning
      - alert: KubeDaemonSetRolloutStuck
        annotations:
          message: Only {{ $value | humanizePercentage }} of the desired Pods of DaemonSet
            {{ $labels.namespace }}/{{ $labels.daemonset }} are scheduled and ready.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
        expr: |
          kube_daemonset_status_number_ready{job="kube-state-metrics"}
            /
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} < 1.00
        for: 15m
        labels:
          severity: warning
      - alert: KubeContainerWaiting
        annotations:
          message: Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container}}
            has been in waiting state for longer than 1 hour.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
        expr: |
          sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics"}) > 0
        for: 1h
        labels:
          severity: warning
      - alert: KubeDaemonSetNotScheduled
        annotations:
          message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
            }} are not scheduled.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
        expr: |
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            -
          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
        for: 10m
        labels:
          severity: warning
      - alert: KubeDaemonSetMisScheduled
        annotations:
          message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
            }} are running where they are not supposed to run.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
        expr: |
          kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
        for: 15m
        labels:
          severity: warning
      - alert: KubeJobCompletion
        annotations:
          message: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more
            than one hour to complete.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion
        expr: |
          kube_job_spec_completions{job="kube-state-metrics"} - kube_job_status_succeeded{job="kube-state-metrics"}  > 0
        for: 1h
        labels:
          severity: warning
      - alert: KubeJobFailed
        annotations:
          message: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
        expr: |
          kube_job_failed{job="kube-state-metrics"}  > 0
        for: 15m
        labels:
          severity: warning
      - alert: KubeHpaReplicasMismatch
        annotations:
          message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has not matched the
            desired number of replicas for longer than 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch
        expr: |
          (kube_hpa_status_desired_replicas{job="kube-state-metrics"}
            !=
          kube_hpa_status_current_replicas{job="kube-state-metrics"})
            and
          changes(kube_hpa_status_current_replicas[15m]) == 0
        for: 15m
        labels:
          severity: warning
      - alert: KubeHpaMaxedOut
        annotations:
          message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has been running at
            max replicas for longer than 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout
        expr: |
          kube_hpa_status_current_replicas{job="kube-state-metrics"}
            ==
          kube_hpa_spec_max_replicas{job="kube-state-metrics"}
        for: 15m
        labels:
          severity: warning
    - name: kubernetes-resources
      rules:
      - alert: KubeCPUOvercommit
        annotations:
          message: Cluster has overcommitted CPU resource requests for Pods and cannot
            tolerate node failure.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
        expr: |
          sum(namespace:kube_pod_container_resource_requests_cpu_cores:sum{})
            /
          sum(kube_node_status_allocatable_cpu_cores)
            >
          (count(kube_node_status_allocatable_cpu_cores)-1) / count(kube_node_status_allocatable_cpu_cores)
        for: 5m
        labels:
          severity: warning
      - alert: KubeMemoryOvercommit
        annotations:
          message: Cluster has overcommitted memory resource requests for Pods and cannot
            tolerate node failure.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryovercommit
        expr: |
          sum(namespace:kube_pod_container_resource_requests_memory_bytes:sum{})
            /
          sum(kube_node_status_allocatable_memory_bytes)
            >
          (count(kube_node_status_allocatable_memory_bytes)-1)
            /
          count(kube_node_status_allocatable_memory_bytes)
        for: 5m
        labels:
          severity: warning
      - alert: KubeCPUQuotaOvercommit
        annotations:
          message: Cluster has overcommitted CPU resource requests for Namespaces.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuquotaovercommit
        expr: |
          sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="cpu"})
            /
          sum(kube_node_status_allocatable_cpu_cores)
            > 1.5
        for: 5m
        labels:
          severity: warning
      - alert: KubeMemoryQuotaOvercommit
        annotations:
          message: Cluster has overcommitted memory resource requests for Namespaces.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryquotaovercommit
        expr: |
          sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="memory"})
            /
          sum(kube_node_status_allocatable_memory_bytes{job="node-exporter"})
            > 1.5
        for: 5m
        labels:
          severity: warning
      - alert: KubeQuotaFullyUsed
        annotations:
          message: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage
            }} of its {{ $labels.resource }} quota.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotafullyused
        expr: |
          kube_resourcequota{job="kube-state-metrics", type="used"}
            / ignoring(instance, job, type)
          (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
            >= 1
        for: 15m
        labels:
          severity: info
      - alert: CPUThrottlingHigh
        annotations:
          message: '{{ $value | humanizePercentage }} throttling of CPU in namespace
            {{ $labels.namespace }} for container {{ $labels.container }} in pod {{
            $labels.pod }}.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh
        expr: |
          sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace)
            /
          sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace)
            > ( 25 / 100 )
        for: 15m
        labels:
          severity: warning
    - name: kubernetes-storage
      rules:
      - alert: KubePersistentVolumeFillingUp
        annotations:
          message: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim
            }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage
            }} free.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup
        expr: |
          kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
            < 0.03
        for: 1m
        labels:
          severity: critical
      - alert: KubePersistentVolumeFillingUp
        annotations:
          message: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim
            }} in Namespace {{ $labels.namespace }} is expected to fill up within four
            days. Currently {{ $value | humanizePercentage }} is available.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup
        expr: |
          (
            kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
              /
            kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
          ) < 0.15
          and
          predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
        for: 1h
        labels:
          severity: warning
      - alert: KubePersistentVolumeErrors
        annotations:
          message: The persistent volume {{ $labels.persistentvolume }} has status {{
            $labels.phase }}.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors
        expr: |
          kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
        for: 5m
        labels:
          severity: critical
    - name: kubernetes-system
      rules:
      - alert: KubeVersionMismatch
        annotations:
          message: There are {{ $value }} different semantic versions of Kubernetes
            components running.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
        expr: |
          count(count by (gitVersion) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"gitVersion","$1","gitVersion","(v[0-9]*.[0-9]*.[0-9]*).*"))) > 1
        for: 15m
        labels:
          severity: warning
      - alert: KubeClientErrors
        annotations:
          message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
            }}' is experiencing {{ $value | humanizePercentage }} errors.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
        expr: |
          (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job)
            /
          sum(rate(rest_client_requests_total[5m])) by (instance, job))
          > 0.01
        for: 15m
        labels:
          severity: warning
    - name: kube-apiserver-slos
      rules:
      - alert: KubeAPIErrorBudgetBurn
        annotations:
          message: The API server is burning too much error budget
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
        expr: |
          sum(apiserver_request:burnrate1h) > (14.40 * 0.01000)
          and
          sum(apiserver_request:burnrate5m) > (14.40 * 0.01000)
        for: 2m
        labels:
          long: 1h
          severity: critical
          short: 5m
      - alert: KubeAPIErrorBudgetBurn
        annotations:
          message: The API server is burning too much error budget
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
        expr: |
          sum(apiserver_request:burnrate6h) > (6.00 * 0.01000)
          and
          sum(apiserver_request:burnrate30m) > (6.00 * 0.01000)
        for: 15m
        labels:
          long: 6h
          severity: critical
          short: 30m
      - alert: KubeAPIErrorBudgetBurn
        annotations:
          message: The API server is burning too much error budget
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
        expr: |
          sum(apiserver_request:burnrate1d) > (3.00 * 0.01000)
          and
          sum(apiserver_request:burnrate2h) > (3.00 * 0.01000)
        for: 1h
        labels:
          long: 1d
          severity: warning
          short: 2h
      - alert: KubeAPIErrorBudgetBurn
        annotations:
          message: The API server is burning too much error budget
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
        expr: |
          sum(apiserver_request:burnrate3d) > (1.00 * 0.01000)
          and
          sum(apiserver_request:burnrate6h) > (1.00 * 0.01000)
        for: 3h
        labels:
          long: 3d
          severity: warning
          short: 6h
    - name: kubernetes-system-apiserver
      rules:
      - alert: KubeClientCertificateExpiration
        annotations:
          message: A client certificate used to authenticate to the apiserver is expiring
            in less than 7.0 days.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
        expr: |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
        labels:
          severity: warning
      - alert: KubeClientCertificateExpiration
        annotations:
          message: A client certificate used to authenticate to the apiserver is expiring
            in less than 24.0 hours.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
        expr: |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
        labels:
          severity: critical
      - alert: AggregatedAPIErrors
        annotations:
          message: An aggregated API {{ $labels.name }}/{{ $labels.namespace }} has
            reported errors. The number of errors have increased for it in the past
            five minutes. High values indicate that the availability of the service
            changes too often.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-aggregatedapierrors
        expr: |
          sum by(name, namespace)(increase(aggregator_unavailable_apiservice_count[5m])) > 2
        labels:
          severity: warning
      - alert: AggregatedAPIDown
        annotations:
          message: An aggregated API {{ $labels.name }}/{{ $labels.namespace }} is down.
            It has not been available at least for the past five minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-aggregatedapidown
        expr: |
          sum by(name, namespace)(sum_over_time(aggregator_unavailable_apiservice[5m])) > 0
        for: 5m
        labels:
          severity: warning
      - alert: KubeAPIDown
        annotations:
          message: KubeAPI has disappeared from Prometheus target discovery.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
        expr: |
          absent(up{job="apiserver"} == 1)
        for: 15m
        labels:
          severity: critical
    - name: kubernetes-system-kubelet
      rules:
      - alert: KubeNodeNotReady
        annotations:
          message: '{{ $labels.node }} has been unready for more than 15 minutes.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
        expr: |
          kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
        for: 15m
        labels:
          severity: warning
      - alert: KubeNodeUnreachable
        annotations:
          message: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable
        expr: |
          (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key="ToBeDeletedByClusterAutoscaler"}) == 1
        labels:
          severity: warning
      - alert: KubeletTooManyPods
        annotations:
          message: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage
            }} of its Pod capacity.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
        expr: |
          max(max(kubelet_running_pod_count{job="kubelet", metrics_path="/metrics"}) by(instance) * on(instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"}) by(node) / max(kube_node_status_capacity_pods{job="kube-state-metrics"} != 1) by(node) > 0.95
        for: 15m
        labels:
          severity: warning
      - alert: KubeNodeReadinessFlapping
        annotations:
          message: The readiness status of node {{ $labels.node }} has changed {{ $value
            }} times in the last 15 minutes.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodereadinessflapping
        expr: |
          sum(changes(kube_node_status_condition{status="true",condition="Ready"}[15m])) by (node) > 2
        for: 15m
        labels:
          severity: warning
      - alert: KubeletPlegDurationHigh
        annotations:
          message: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration
            of {{ $value }} seconds on node {{ $labels.node }}.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletplegdurationhigh
        expr: |
          node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
        for: 5m
        labels:
          severity: warning
      - alert: KubeletPodStartUpLatencyHigh
        annotations:
          message: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds
            on node {{ $labels.node }}.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletpodstartuplatencyhigh
        expr: |
          histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (instance, le)) * on(instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"} > 60
        for: 15m
        labels:
          severity: warning
      - alert: KubeletDown
        annotations:
          message: Kubelet has disappeared from Prometheus target discovery.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
        expr: |
          absent(up{job="kubelet", metrics_path="/metrics"} == 1)
        for: 15m
        labels:
          severity: critical
    - name: kubernetes-system-scheduler
      rules:
      - alert: KubeSchedulerDown
        annotations:
          message: KubeScheduler has disappeared from Prometheus target discovery.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown
        expr: |
          absent(up{job="kube-scheduler"} == 1)
        for: 15m
        labels:
          severity: critical
    - name: kubernetes-system-controller-manager
      rules:
      - alert: KubeControllerManagerDown
        annotations:
          message: KubeControllerManager has disappeared from Prometheus target discovery.
          runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown
        expr: |
          absent(up{job="kube-controller-manager"} == 1)
        for: 15m
        labels:
          severity: critical
    - name: prometheus
      rules:
      - alert: PrometheusBadConfig
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to
            reload its configuration.
          summary: Failed Prometheus configuration reload.
        expr: |
          # Without max_over_time, failed scrapes could create false negatives, see
          # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          max_over_time(prometheus_config_last_reload_successful{job="prometheus-k8s",namespace="monitoring"}[5m]) == 0
        for: 10m
        labels:
          severity: critical
      - alert: PrometheusNotificationQueueRunningFull
        annotations:
          description: Alert notification queue of Prometheus {{$labels.namespace}}/{{$labels.pod}}
            is running full.
          summary: Prometheus alert notification queue predicted to run full in less
            than 30m.
        expr: |
          # Without min_over_time, failed scrapes could create false negatives, see
          # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          (
            predict_linear(prometheus_notifications_queue_length{job="prometheus-k8s",namespace="monitoring"}[5m], 60 * 30)
          >
            min_over_time(prometheus_notifications_queue_capacity{job="prometheus-k8s",namespace="monitoring"}[5m])
          )
        for: 15m
        labels:
          severity: warning
      - alert: PrometheusErrorSendingAlertsToSomeAlertmanagers
        annotations:
          description: '{{ printf "%.1f" $value }}% errors while sending alerts from
            Prometheus {{$labels.namespace}}/{{$labels.pod}} to Alertmanager {{$labels.alertmanager}}.'
          summary: Prometheus has encountered more than 1% errors sending alerts to
            a specific Alertmanager.
        expr: |
          (
            rate(prometheus_notifications_errors_total{job="prometheus-k8s",namespace="monitoring"}[5m])
          /
            rate(prometheus_notifications_sent_total{job="prometheus-k8s",namespace="monitoring"}[5m])
          )
          * 100
          > 1
        for: 15m
        labels:
          severity: warning
      - alert: PrometheusErrorSendingAlertsToAnyAlertmanager
        annotations:
          description: '{{ printf "%.1f" $value }}% minimum errors while sending alerts
            from Prometheus {{$labels.namespace}}/{{$labels.pod}} to any Alertmanager.'
          summary: Prometheus encounters more than 3% errors sending alerts to any Alertmanager.
        expr: |
          min without(alertmanager) (
            rate(prometheus_notifications_errors_total{job="prometheus-k8s",namespace="monitoring"}[5m])
          /
            rate(prometheus_notifications_sent_total{job="prometheus-k8s",namespace="monitoring"}[5m])
          )
          * 100
          > 3
        for: 15m
        labels:
          severity: critical
      - alert: PrometheusNotConnectedToAlertmanagers
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not connected
            to any Alertmanagers.
          summary: Prometheus is not connected to any Alertmanagers.
        expr: |
          # Without max_over_time, failed scrapes could create false negatives, see
          # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          max_over_time(prometheus_notifications_alertmanagers_discovered{job="prometheus-k8s",namespace="monitoring"}[5m]) < 1
        for: 10m
        labels:
          severity: warning
      - alert: PrometheusTSDBReloadsFailing
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
            {{$value | humanize}} reload failures over the last 3h.
          summary: Prometheus has issues reloading blocks from disk.
        expr: |
          increase(prometheus_tsdb_reloads_failures_total{job="prometheus-k8s",namespace="monitoring"}[3h]) > 0
        for: 4h
        labels:
          severity: warning
      - alert: PrometheusTSDBCompactionsFailing
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
            {{$value | humanize}} compaction failures over the last 3h.
          summary: Prometheus has issues compacting blocks.
        expr: |
          increase(prometheus_tsdb_compactions_failed_total{job="prometheus-k8s",namespace="monitoring"}[3h]) > 0
        for: 4h
        labels:
          severity: warning
      - alert: PrometheusNotIngestingSamples
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not ingesting
            samples.
          summary: Prometheus is not ingesting samples.
        expr: |
          rate(prometheus_tsdb_head_samples_appended_total{job="prometheus-k8s",namespace="monitoring"}[5m]) <= 0
        for: 10m
        labels:
          severity: warning
      - alert: PrometheusDuplicateTimestamps
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping
            {{ printf "%.4g" $value  }} samples/s with different values but duplicated
            timestamp.
          summary: Prometheus is dropping samples with duplicate timestamps.
        expr: |
          rate(prometheus_target_scrapes_sample_duplicate_timestamp_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
        for: 10m
        labels:
          severity: warning
      - alert: PrometheusOutOfOrderTimestamps
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping
            {{ printf "%.4g" $value  }} samples/s with timestamps arriving out of order.
          summary: Prometheus drops samples with out-of-order timestamps.
        expr: |
          rate(prometheus_target_scrapes_sample_out_of_order_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
        for: 10m
        labels:
          severity: warning
      - alert: PrometheusRemoteStorageFailures
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} failed to send
            {{ printf "%.1f" $value }}% of the samples to {{ $labels.remote_name}}:{{
            $labels.url }}
          summary: Prometheus fails to send samples to remote storage.
        expr: |
          (
            rate(prometheus_remote_storage_failed_samples_total{job="prometheus-k8s",namespace="monitoring"}[5m])
          /
            (
              rate(prometheus_remote_storage_failed_samples_total{job="prometheus-k8s",namespace="monitoring"}[5m])
            +
              rate(prometheus_remote_storage_succeeded_samples_total{job="prometheus-k8s",namespace="monitoring"}[5m])
            )
          )
          * 100
          > 1
        for: 15m
        labels:
          severity: critical
      - alert: PrometheusRemoteWriteBehind
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write
            is {{ printf "%.1f" $value }}s behind for {{ $labels.remote_name}}:{{ $labels.url
            }}.
          summary: Prometheus remote write is behind.
        expr: |
          # Without max_over_time, failed scrapes could create false negatives, see
          # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          (
            max_over_time(prometheus_remote_storage_highest_timestamp_in_seconds{job="prometheus-k8s",namespace="monitoring"}[5m])
          - on(job, instance) group_right
            max_over_time(prometheus_remote_storage_queue_highest_sent_timestamp_seconds{job="prometheus-k8s",namespace="monitoring"}[5m])
          )
          > 120
        for: 15m
        labels:
          severity: critical
      - alert: PrometheusRemoteWriteDesiredShards
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write
            desired shards calculation wants to run {{ $value }} shards for queue {{
            $labels.remote_name}}:{{ $labels.url }}, which is more than the max of {{
            printf `prometheus_remote_storage_shards_max{instance="%s",job="prometheus-k8s",namespace="monitoring"}`
            $labels.instance | query | first | value }}.
          summary: Prometheus remote write desired shards calculation wants to run more
            than configured max shards.
        expr: |
          # Without max_over_time, failed scrapes could create false negatives, see
          # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          (
            max_over_time(prometheus_remote_storage_shards_desired{job="prometheus-k8s",namespace="monitoring"}[5m])
          >
            max_over_time(prometheus_remote_storage_shards_max{job="prometheus-k8s",namespace="monitoring"}[5m])
          )
        for: 15m
        labels:
          severity: warning
      - alert: PrometheusRuleFailures
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to
            evaluate {{ printf "%.0f" $value }} rules in the last 5m.
          summary: Prometheus is failing rule evaluations.
        expr: |
          increase(prometheus_rule_evaluation_failures_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
        for: 15m
        labels:
          severity: critical
      - alert: PrometheusMissingRuleEvaluations
        annotations:
          description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has missed {{
            printf "%.0f" $value }} rule group evaluations in the last 5m.
          summary: Prometheus is missing rule evaluations due to slow rule group evaluation.
        expr: |
          increase(prometheus_rule_group_iterations_missed_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
        for: 15m
        labels:
          severity: warning
    - name: alertmanager.rules
      rules:
      - alert: AlertmanagerConfigInconsistent
        annotations:
          message: |
            The configuration of the instances of the Alertmanager cluster `{{ $labels.namespace }}/{{ $labels.service }}` are out of sync.
            {{ range printf "alertmanager_config_hash{namespace=\"%s\",service=\"%s\"}" $labels.namespace $labels.service | query }}
            Configuration hash for pod {{ .Labels.pod }} is "{{ printf "%.f" .Value }}"
            {{ end }}
        expr: |
          count by(namespace,service) (count_values by(namespace,service) ("config_hash", alertmanager_config_hash{job="alertmanager-main",namespace="monitoring"})) != 1
        for: 5m
        labels:
          severity: critical
      - alert: AlertmanagerFailedReload
        annotations:
          message: Reloading Alertmanager's configuration has failed for {{ $labels.namespace
            }}/{{ $labels.pod}}.
        expr: |
          alertmanager_config_last_reload_successful{job="alertmanager-main",namespace="monitoring"} == 0
        for: 10m
        labels:
          severity: warning
      - alert: AlertmanagerMembersInconsistent
        annotations:
          message: Alertmanager has not found all other members of the cluster.
        expr: |
          alertmanager_cluster_members{job="alertmanager-main",namespace="monitoring"}
            != on (service) GROUP_LEFT()
          count by (service) (alertmanager_cluster_members{job="alertmanager-main",namespace="monitoring"})
        for: 5m
        labels:
          severity: critical
    - name: general.rules
      rules:
      - alert: TargetDown
        annotations:
          message: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service
            }} targets in {{ $labels.namespace }} namespace are down.'
        expr: 100 * (count(up == 0) BY (job, namespace, service) / count(up) BY (job,
          namespace, service)) > 10
        for: 10m
        labels:
          severity: warning
      - alert: Watchdog
        annotations:
          message: |
            This is an alert meant to ensure that the entire alerting pipeline is functional.
            This alert is always firing, therefore it should always be firing in Alertmanager
            and always fire against a receiver. There are integrations with various notification
            mechanisms that send a notification when this alert is not firing. For example the
            "DeadMansSnitch" integration in PagerDuty.
        expr: vector(1)
        labels:
          severity: none
    - name: node-network
      rules:
      - alert: NodeNetworkInterfaceFlapping
        annotations:
          message: Network interface "{{ $labels.device }}" changing it's up status
            often on node-exporter {{ $labels.namespace }}/{{ $labels.pod }}"
        expr: |
          changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) > 2
        for: 2m
        labels:
          severity: warning
---
apiVersion: v1
data:
  prometheus.yml: |
    global:
      scrape_interval: 5s
    rule_files:
      - "/etc/prometheus-rules/alert.rules"
    alerting:
      alertmanagers:
        - static_configs:
          - targets: ["alertmanager:9093"]
    scrape_configs:
      - job_name: 'chaos-exporter'
        static_configs:
          - targets: ['chaos-exporter.hce.svc.cluster.local:8080']
        relabel_configs:
          - target_label: instance
            replacement: 'chaos-exporter-service'
      - job_name: 'mysql_server1'
        static_configs:
          - targets: ['mysql-exporter.monitoring.svc.cluster.local:9104']
            labels:
              alias: db1
      - job_name: prometheus-blackbox-exporter-http
        scrape_interval: 1s
        metrics_path: /metrics
        params:
          module: [http_2xx]
        static_configs:
          - targets:
            - frontend.boutique.svc.cluster.local:80
            - productcatalogservice.boutique.svc.cluster.local:3550
            - adservice.boutique.svc.cluster.local:9555
            - cartservice.boutique.svc.cluster.local:7070
            - checkoutservice.boutique.svc.cluster.local:5050
            - currencyservice.boutique.svc.cluster.local:7000
            - emailservice.boutique.svc.cluster.local:5000
            - paymentservice.boutique.svc.cluster.local:50051
            - recommendationservice.boutique.svc.cluster.local:8080
            - redis-cart.boutique.svc.cluster.local:6379
            - shippingservice.boutique.svc.cluster.local:50051
      - job_name: prometheus-blackbox-exporter
        scrape_interval: 1s
        metrics_path: /probe
        params:
          module: [http_2xx]
        static_configs:
          - targets:
            - frontend.boutique.svc.cluster.local:80
            - productcatalogservice.boutique.svc.cluster.local:3550
            - adservice.boutique.svc.cluster.local:9555
            - cartservice.boutique.svc.cluster.local:7070
            - checkoutservice.boutique.svc.cluster.local:5050
            - currencyservice.boutique.svc.cluster.local:7000
            - emailservice.boutique.svc.cluster.local:5000
            - paymentservice.boutique.svc.cluster.local:50051
            - recommendationservice.boutique.svc.cluster.local:8080
            - redis-cart.boutique.svc.cluster.local:6379
            - shippingservice.boutique.svc.cluster.local:50051
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: 'prometheus-blackbox-exporter:9115'
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics:8080']
      - job_name: 'node-exporter'
        static_configs:
          - targets: ['node-exporter:9100']
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
        - source_labels: [__meta_kubernetes_endpoints_name]
          regex: 'node-exporter'
          action: keep
      - job_name: 'cAdvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
      - job_name: kubernetes-service-endpoints
        kubernetes_sd_configs:
          - role: endpoints
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_service_label_component
            regex: apiserver
            action: replace
            target_label: __scheme__
            replacement: https
          - source_labels:
              - __meta_kubernetes_service_label_kubernetes_io_cluster_service
            action: drop
            regex: 'true'
          - source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scrape
            action: drop
            regex: 'false'
          - source_labels:
              - __meta_kubernetes_pod_container_port_name
            action: drop
            regex: .*-noscrape
          - source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scheme
            action: replace
            target_label: __scheme__
            regex: ^(https?)$
            replacement: $1
          - source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_path
            action: replace
            target_label: __metrics_path__
            regex: ^(.+)$
            replacement: $1
          - source_labels:
              - __address__
              - __meta_kubernetes_service_annotation_prometheus_io_port
            action: replace
            target_label: __address__
            regex: '^(.+)(?::\d+);(\d+)$'
            replacement: '$1:$2'
          - action: labelmap
            regex: ^__meta_kubernetes_service_label_(.+)$
            replacement: $1
          - source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
            separator: /
            target_label: job
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scrape
            action: keep
            regex: 'true'
          - source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_pod_label_name
            separator: /
            target_label: job
          - source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node
      - job_name: kubernetes-nodes
        kubernetes_sd_configs:
          - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - target_label: __scheme__
            replacement: https
          - source_labels:
              - __meta_kubernetes_node_label_kubernetes_io_hostname
            target_label: instance
      - job_name: weave
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_pod_label_name
            action: drop
            regex: ^kube-system;weave-net$
          - source_labels:
              - __meta_kubernetes_pod_container_name
              - __address__
            action: replace
            target_label: __address__
            regex: '^weave;(.+?)(?::\d+)?$'
            replacement: '$1:6782'
          - source_labels:
              - __meta_kubernetes_pod_container_name
              - __address__
            action: replace
            target_label: __address__
            regex: '^weave-npc;(.+?)(?::\d+)?$'
            replacement: '$1:6781'
          - source_labels:
              - __meta_kubernetes_pod_container_name
            action: replace
            target_label: job
kind: ConfigMap
metadata:
  name: prometheus-configmap
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
      name: prometheus
    spec:
      containers:
        - args:
            - --storage.tsdb.retention.time=360h
            - --config.file=/etc/prometheus/prometheus.yml
          image: prom/prometheus:v2.25.2
          imagePullPolicy: IfNotPresent
          name: prometheus
          ports:
            - containerPort: 9090
              name: web
              protocol: TCP
          volumeMounts:
            - mountPath: /etc/prometheus
              name: config-volume
            - mountPath: /etc/prometheus-rules
              name: alertrules-volume
      serviceAccount: prometheus
      serviceAccountName: prometheus
      volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-configmap
          name: config-volume
        - configMap:
            defaultMode: 420
            name: prometheus-alertrules
          name: alertrules-volume
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
  labels:
    name: prometheus-k8s
  name: prometheus-k8s

spec:
  selector:
    app: prometheus
  type: LoadBalancer
  ports:
    - name: prometheus
      protocol: TCP
      port: 9090
      targetPort: 9090
      # nodePort: 31090
---
## Exporter Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-blackbox-exporter
  labels:
    app: prometheus-blackbox-exporter
data:
  blackbox.yaml: |
    modules:
      http_2xx:
        http:
          no_follow_redirects: false
          preferred_ip_protocol: ip4
          valid_http_versions:
          - HTTP/1.1
          - HTTP/2
          valid_status_codes: []
        prober: http
        timeout: 5s
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-blackbox-exporter
  labels:
    app: prometheus-blackbox-exporter
    release: prometheus-stack
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-blackbox-exporter
  template:
    metadata:
      labels:
        app: prometheus-blackbox-exporter
        release: prometheus-stack
    spec:
      restartPolicy: Always
      containers:
        - name: blackbox-exporter
          image: 'prom/blackbox-exporter:v0.15.1'
          imagePullPolicy: IfNotPresent
          securityContext:
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          args:
            - '--config.file=/config/blackbox.yaml'
          resources: {}
          ports:
            - containerPort: 9115
              name: http
          livenessProbe:
            httpGet:
              path: /health
              port: http
          readinessProbe:
            httpGet:
              path: /health
              port: http
          volumeMounts:
            - mountPath: /config
              name: config
        - name: configmap-reload
          image: 'jimmidyson/configmap-reload:v0.2.2'
          imagePullPolicy: 'IfNotPresent'
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
          args:
            - --volume-dir=/etc/config
            - --webhook-url=http://localhost:9115/-/reload
          resources: {}
          volumeMounts:
            - mountPath: /etc/config
              name: config
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: prometheus-blackbox-exporter
---
kind: Service
apiVersion: v1
metadata:
  name: prometheus-blackbox-exporter
  labels:
    app: prometheus-blackbox-exporter
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9115
      protocol: TCP
  selector:
    app: prometheus-blackbox-exporter
---
##Grafana Configuration
##Dashboard Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: litmus-grafana-provisioner
data:
  default.yaml: |-
    {
        "apiVersion": 1,
        "providers": [
            {
                "name": "Prometheus",
                "orgId": 1,
                "folder": "Services",
                "type": "file",
                "disableDeletion": false,
                "editable": true,
                "options": {
                    "path": "/var/lib/grafana/dashboards",
                    "foldersFromFilesStructure": true
                }
            }
        ]
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: litmus-grafana-dashboards
  labels:
    grafana_dashboard: "1"
data:
  node_pod_metrics_dashboard.json: |-
    {"annotations":{"list":[{"$$hashKey":"object:137","builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":true,"iconColor":"rgba(0, 211, 255, 1)","name":"Annotations & Alerts","type":"dashboard"},{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=\"catalogue-pod-cpu-hog-pod-cpu-hog\", chaosresult_namespace=\"litmus\"}","hide":false,"iconColor":"rgba(255, 96, 96, 1)","name":"catalogue-pod-cpu-hog","showIn":0,"step":"1s","tagKeys":"litmus, chaos","textFormat":"pod-cpu-hog","titleFormat":"catalogue-chaos"},{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=\"orders-pod-memory-hog-pod-memory-hog\", chaosresult_namespace=\"litmus\"}","hide":false,"iconColor":"rgba(255, 96, 96, 1)","name":"orders-pod-memory-hog","showIn":0,"step":"1s","tagKeys":"litmus, chaos","textFormat":"pod-memory-hog","titleFormat":"orders-chaos"},{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=\"orders-node-memory-hog-node-memory-hog\",chaosresult_namespace=\"litmus\"}","hide":false,"iconColor":"rgba(255, 96, 96, 1)","name":"orders-node-memory-hog","showIn":0,"step":"1s","tagKeys":"litmus, chaos","textFormat":"node-memory-hog","titleFormat":"orders-chaos","useValueForTime":false},{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=\"catalogue-node-cpu-hog-node-cpu-hog\",chaosresult_namespace=\"litmus\"}","hide":false,"iconColor":"rgba(255, 96, 96, 1)","name":"catalogue-node-cpu-hog","showIn":0,"step":"1s","tagKeys":"litmus, chaos","textFormat":"node-cpu-hog","titleFormat":"catalogue-chaos"}]},"editable":true,"gnetId":null,"graphTooltip":0,"id":3,"iteration":1615817690444,"links":[],"panels":[{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":0},"id":47,"panels":[],"title":"Litmus Chaos Chaos durations interleaved with Node Exporter & Kube-State Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$datasource","fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":16,"w":12,"x":0,"y":1},"hiddenSeries":false,"id":64,"interval":"","legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"sort":"current","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":1,"nullPointMode":"connected","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"instance:node_cpu_utilisation:rate1m","interval":"","legendFormat":"\"{{instance}}\"","refId":"B"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos - Node - CPU Utilization","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:92","format":"percentunit","label":"cores","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:93","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$datasource","fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":16,"w":12,"x":12,"y":1},"hiddenSeries":false,"id":65,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"sort":"current","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":1,"nullPointMode":"null as zero","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"instance:node_memory_utilisation:ratio","interval":"","legendFormat":"\"{{instance}}\"","refId":"B"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos - Node - Memory Utilization","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:251","format":"percentunit","label":"Memory","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:252","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$datasource","fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":13,"w":12,"x":0,"y":17},"hiddenSeries":false,"id":62,"interval":"","legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"sort":"current","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":1,"nullPointMode":"connected","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",pod!=\"\"}[5m])) by (pod)","interval":"","legendFormat":"\"{{pod}}\"","refId":"B"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos - Pod - CPU Usage","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:535","format":"short","label":"cores","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:536","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$datasource","fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":13,"w":12,"x":12,"y":17},"hiddenSeries":false,"id":63,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"sort":"current","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":1,"nullPointMode":"connected","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(container_memory_usage_bytes{container!=\"POD\",container!=\"\"}) by (pod)","interval":"","legendFormat":"\"{{pod}}\"","refId":"B"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos - Pod - Memory Usage","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:665","format":"bytes","label":"Memory","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:666","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":false}],"yaxis":{"align":false,"alignLevel":null}}],"refresh":"5s","schemaVersion":27,"style":"dark","tags":[],"templating":{"list":[{"current":{"selected":false,"text":"DS_PROMETHEUS","value":"DS_PROMETHEUS"},"description":null,"error":null,"hide":0,"includeAll":false,"label":"","multi":false,"name":"datasource","options":[],"query":"prometheus","queryValue":"","refresh":1,"regex":"","skipUrlSync":false,"type":"datasource"},{"allValue":null,"current":{"isNone":true,"selected":false,"text":"None","value":""},"datasource":"$datasource","definition":"label_values(kube_pod_info, cluster)","description":null,"error":null,"hide":2,"includeAll":false,"label":null,"multi":false,"name":"cluster","options":[],"query":{"query":"label_values(kube_pod_info, cluster)","refId":"DS_PROMETHEUS-cluster-Variable-Query"},"refresh":1,"regex":"","skipUrlSync":false,"sort":1,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false}]},"time":{"from":"now-30m","to":"now"},"timepicker":{"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"]},"timezone":"","title":"Node and Pod Chaos Metrics","uid":"nodepodmetrics","version":1}
  mysql_overview_dashboard.json: |-
    {"annotations":{"list":[{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=\"percona-network-chaos-pod-network-loss\", chaosresult_namespace=\"litmus\"}","hide":false,"iconColor":"rgba(255, 96, 96, 1)","name":"Litmus Chaos","showIn":0,"step":"1s","tagKeys":"chaos","textFormat":"percona-network-chaos","titleFormat":"percona-network-chaos","useValueForTime":false},{"builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":false,"iconColor":"#e0752d","limit":100,"name":"PMM Annotations","showIn":0,"tags":["pmm_annotation"],"type":"tags"},{"builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":true,"iconColor":"#6ed0e0","limit":100,"name":"Annotations & Alerts","showIn":0,"tags":[],"type":"dashboard"}]},"editable":true,"gnetId":null,"graphTooltip":1,"id":3,"iteration":1615977270377,"links":[{"icon":"dashboard","includeVars":true,"keepTime":true,"tags":["QAN"],"targetBlank":false,"title":"Query Analytics","type":"link","url":"\/graph\/dashboard\/db\/_pmm-query-analytics"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["OS"],"targetBlank":false,"title":"OS","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["MySQL"],"targetBlank":false,"title":"MySQL","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["MongoDB"],"targetBlank":false,"title":"MongoDB","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["PostgreSQL"],"targetBlank":false,"title":"PostgreSQL","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["HA"],"targetBlank":false,"title":"HA","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["Cloud"],"targetBlank":false,"title":"Cloud","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["Insight"],"targetBlank":false,"title":"Insight","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["PMM"],"targetBlank":false,"title":"PMM","type":"dashboards"}],"panels":[{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":0},"id":382,"panels":[],"repeat":null,"title":"","type":"row"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["rgba(245, 54, 54, 0.9)","rgba(237, 129, 40, 0.89)","rgba(50, 172, 45, 0.97)"],"datasource":"DS_PROMETHEUS","decimals":1,"description":"**MySQL Uptime**\n\nThe amount of time since the last restart of the MySQL server process.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"s","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":6,"x":0,"y":1},"height":"125px","id":12,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"s","postfixFontSize":"80%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":false},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_uptime{instance=~\"$host\"}","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"300,3600","title":"MySQL Uptime","type":"singlestat","valueFontSize":"80%","valueMaps":[],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":false,"colors":["rgba(245, 54, 54, 0.9)","rgba(237, 129, 40, 0.89)","rgba(50, 172, 45, 0.97)"],"datasource":"DS_PROMETHEUS","decimals":2,"description":"**Current QPS**\n\nBased on the queries reported by MySQL's ``SHOW STATUS`` command, it is the number of statements executed by the server within the last second. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count \n``COM_PING`` or ``COM_STATISTICS`` commands.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"short","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":6,"x":6,"y":1},"height":"125px","id":13,"interval":"$interval","links":[{"targetBlank":true,"title":"MySQL Server Status Variables","url":"https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/server-status-variables.html#statvar_Queries"}],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_queries{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_queries{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":20}],"thresholds":"35,75","title":"Current QPS","type":"singlestat","valueFontSize":"80%","valueMaps":[],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":false,"colors":["rgba(50, 172, 45, 0.97)","rgba(237, 129, 40, 0.89)","rgba(245, 54, 54, 0.9)"],"datasource":"DS_PROMETHEUS","decimals":0,"description":"**InnoDB Buffer Pool Size**\n\nInnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"bytes","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":6,"x":12,"y":1},"height":"125px","id":51,"interval":"$interval","links":[{"targetBlank":true,"title":"Tuning the InnoDB Buffer Pool Size","url":"https:\/\/www.percona.com\/blog\/2015\/06\/02\/80-ram-tune-innodb_buffer_pool_size\/"}],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":false},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_innodb_buffer_pool_size{instance=~\"$host\"}","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"90,95","title":"InnoDB Buffer Pool Size","type":"singlestat","valueFontSize":"80%","valueMaps":[],"valueName":"current"},{"cacheTimeout":null,"datasource":"DS_PROMETHEUS","description":"**Total RAM per Node n MiB**\n\nInnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.","fieldConfig":{"defaults":{"custom":{},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]}},"overrides":[]},"gridPos":{"h":2,"w":6,"x":18,"y":1},"id":52,"interval":"$interval","links":[{"targetBlank":true,"title":"Tuning the InnoDB Buffer Pool Size","url":"https:\/\/www.percona.com\/blog\/2015\/06\/02\/80-ram-tune-innodb_buffer_pool_size\/"}],"maxDataPoints":100,"options":{"colorMode":"value","graphMode":"area","justifyMode":"auto","orientation":"auto","reduceOptions":{"calcs":["mean"],"fields":"","values":false},"text":{},"textMode":"auto"},"pluginVersion":"7.4.3","repeat":null,"targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"node_memory_MemTotal_bytes \/ 1049000","format":"table","instant":true,"interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"timeFrom":null,"timeShift":null,"title":"Total RAM per Node in MiB","type":"stat"},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":3},"id":383,"panels":[],"repeat":null,"title":"Connections","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":0,"description":"**Max Connections** \n\nMax Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that mysqld requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.\n\nmysqld actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.\n\nMax Used Connections is the maximum number of connections that have been in use simultaneously since the server started.\n\nConnections is the number of connection attempts (successful or not) to the MySQL server.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":4},"height":"250px","hiddenSeries":false,"id":92,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"targetBlank":true,"title":"MySQL Server System Variables","url":"https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/server-system-variables.html#sysvar_max_connections"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Max Connections","fill":0}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"max(max_over_time(mysql_global_status_threads_connected{instance=~\"$host\"}[$interval])  or mysql_global_status_threads_connected{instance=~\"$host\"} )","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Connections","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_max_used_connections{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Max Used Connections","metric":"","refId":"C","step":20,"target":""},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_max_connections{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Max Connections","metric":"","refId":"B","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Connections","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Active Threads**\n\nThreads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":4},"hiddenSeries":false,"id":10,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Peak Threads Running","color":"#E24D42","lines":false,"pointradius":1,"points":true},{"alias":"Peak Threads Connected","color":"#1F78C1"},{"alias":"Avg Threads Running","color":"#EAB839"}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"max_over_time(mysql_global_status_threads_connected{instance=~\"$host\"}[$interval]) or\nmax_over_time(mysql_global_status_threads_connected{instance=~\"$host\"}[5m])","format":"time_series","hide":false,"interval":"$interval","intervalFactor":1,"legendFormat":"Peak Threads Connected","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"max_over_time(mysql_global_status_threads_running{instance=~\"$host\"}[$interval]) or\nmax_over_time(mysql_global_status_threads_running{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Peak Threads Running","metric":"","refId":"B","step":20},{"expr":"avg_over_time(mysql_global_status_threads_running{instance=~\"$host\"}[$interval]) or \navg_over_time(mysql_global_status_threads_running{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Avg Threads Running","refId":"C","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Client Thread Activity","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":["total"]},"yaxes":[{"format":"short","label":"Threads","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":11},"id":384,"panels":[],"repeat":null,"title":"Table Locks","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Questions**\n\nThe number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries used in the QPS calculation. \n\nThis variable does not count the following commands:\n* ``COM_PING``\n* ``COM_STATISTICS``\n* ``COM_STMT_PREPARE``\n* ``COM_STMT_CLOSE``\n* ``COM_STMT_RESET``","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":12},"hiddenSeries":false,"id":53,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"targetBlank":true,"title":"MySQL Queries and Questions","url":"https:\/\/www.percona.com\/blog\/2014\/05\/29\/how-mysql-queries-and-questions-are-measured\/"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_questions{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_questions{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Questions","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Questions","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Thread Cache**\n\nThe thread_cache_size variable sets how many threads the server should cache to reuse. When a client disconnects, the client's threads are put in the cache if the cache is not full. It is autosized in MySQL 5.6.8 and above (capped to 100). Requests for threads are satisfied by reusing threads taken from the cache if possible, and only when the cache is empty is a new thread created.\n\n* *Threads_created*: The number of threads created to handle connections.\n* *Threads_cached*: The number of threads in the thread cache.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":12},"hiddenSeries":false,"id":11,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Tuning information","url":"https:\/\/dev.mysql.com\/doc\/refman\/5.6\/en\/server-system-variables.html#sysvar_thread_cache_size"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Threads Created","fill":0}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_thread_cache_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Thread Cache Size","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_threads_cached{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Threads Cached","metric":"","refId":"C","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_threads_created{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_threads_created{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Threads Created","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Thread Cache","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":19},"id":385,"panels":[],"repeat":null,"title":"Temporary Objects","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":20},"hiddenSeries":false,"id":22,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_created_tmp_tables{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_created_tmp_tables{instance=~\"$host\"}[5m])","interval":"$interval","intervalFactor":1,"legendFormat":"Created Tmp Tables","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_created_tmp_disk_tables{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_created_tmp_disk_tables{instance=~\"$host\"}[5m])","interval":"$interval","intervalFactor":1,"legendFormat":"Created Tmp Disk Tables","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_created_tmp_files{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_created_tmp_files{instance=~\"$host\"}[5m])","interval":"$interval","intervalFactor":1,"legendFormat":"Created Tmp Files","metric":"","refId":"C","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Temporary Objects","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Select Types**\n\nAs with most relational databases, selecting based on indexes is more efficient than scanning an entire table's data. Here we see the counters for selects not done with indexes.\n\n* ***Select Scan*** is how many queries caused full table scans, in which all the data in the table had to be read and either discarded or returned.\n* ***Select Range*** is how many queries used a range scan, which means MySQL scanned all rows in a given range.\n* ***Select Full Join*** is the number of joins that are not joined on an index, this is usually a huge performance hit.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":20},"height":"250px","hiddenSeries":false,"id":311,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_select_full_join{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_select_full_join{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Select Full Join","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_select_full_range_join{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_select_full_range_join{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Select Full Range Join","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_select_range{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_select_range{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Select Range","metric":"","refId":"C","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_select_range_check{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_select_range_check{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Select Range Check","metric":"","refId":"D","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_select_scan{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_select_scan{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Select Scan","metric":"","refId":"E","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Select Types","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":27},"id":386,"panels":[],"repeat":null,"title":"Sorts","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Sorts**\n\nDue to a query's structure, order, or other requirements, MySQL sorts the rows before returning them. For example, if a table is ordered 1 to 10 but you want the results reversed, MySQL then has to sort the rows to return 10 to 1.\n\nThis graph also shows when sorts had to scan a whole table or a given range of a table in order to return the results and which could not have been sorted via an index.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":28},"hiddenSeries":false,"id":30,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_sort_rows{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_sort_rows{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Sort Rows","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_sort_range{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_sort_range{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Sort Range","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_sort_merge_passes{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_sort_merge_passes{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Sort Merge Passes","metric":"","refId":"C","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_sort_scan{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_sort_scan{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Sort Scan","metric":"","refId":"D","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Sorts","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Slow Queries**\n\nSlow queries are defined as queries being slower than the long_query_time setting. For example, if you have long_query_time set to 3, all queries that take longer than 3 seconds to complete will show on this graph.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":28},"hiddenSeries":false,"id":48,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_slow_queries{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_slow_queries{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Slow Queries","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Slow Queries","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":35},"id":387,"panels":[],"repeat":null,"title":"Aborted","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**Aborted Connections**\n\nWhen a given host connects to MySQL and the connection is interrupted in the middle (for example due to bad credentials), MySQL keeps that info in a system table (since 5.6 this table is exposed in performance_schema).\n\nIf the amount of failed requests without a successful connection reaches the value of max_connect_errors, mysqld assumes that something is wrong and blocks the host from further connection.\n\nTo allow connections from that host again, you need to issue the ``FLUSH HOSTS`` statement.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":36},"hiddenSeries":false,"id":47,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_aborted_connects{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_aborted_connects{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Aborted Connects (attempts)","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_aborted_clients{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_aborted_clients{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Aborted Clients (timeout)","metric":"","refId":"B","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Aborted Connections","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**Table Locks**\n\nMySQL takes a number of different locks for varying reasons. In this graph we see how many Table level locks MySQL has requested from the storage engine. In the case of InnoDB, many times the locks could actually be row locks as it only takes table level locks in a few specific cases.\n\nIt is most useful to compare Locks Immediate and Locks Waited. If Locks waited is rising, it means you have lock contention. Otherwise, Locks Immediate rising and falling is normal activity.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":36},"hiddenSeries":false,"id":32,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_table_locks_immediate{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_locks_immediate{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Table Locks Immediate","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_table_locks_waited{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_locks_waited{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Table Locks Waited","metric":"","refId":"B","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Table Locks","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":43},"id":388,"panels":[],"repeat":null,"title":"Network","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Network Traffic**\n\nHere we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":44},"hiddenSeries":false,"id":9,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_bytes_received{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_bytes_received{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Inbound","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_bytes_sent{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_bytes_sent{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Outbound","metric":"","refId":"B","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Network Traffic","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"Bps","logBase":1,"max":null,"min":0,"show":true},{"format":"none","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":true,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Network Usage Hourly**\n\nHere we can see how much network traffic is generated by MySQL per hour. You can use the bar graph to compare data sent by MySQL and data received by MySQL.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":44},"height":"250px","hiddenSeries":false,"id":381,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"increase(mysql_global_status_bytes_received{instance=~\"$host\"}[1h])","format":"time_series","interval":"1h","intervalFactor":1,"legendFormat":"Received","metric":"","refId":"A","step":3600},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"increase(mysql_global_status_bytes_sent{instance=~\"$host\"}[1h])","format":"time_series","interval":"1h","intervalFactor":1,"legendFormat":"Sent","metric":"","refId":"B","step":3600}],"thresholds":[],"timeFrom":"24h","timeRegions":[],"timeShift":null,"title":"MySQL Network Usage Hourly","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"bytes","logBase":1,"max":null,"min":0,"show":true},{"format":"none","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":51},"id":389,"panels":[],"repeat":null,"title":"Memory","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":0,"description":"***System Memory***: Total Memory for the system.\\\n***InnoDB Buffer Pool Data***: InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.\\\n***TokuDB Cache Size***: Similar in function to the InnoDB Buffer Pool,  TokuDB will allocate 50% of the installed RAM for its own cache.\\\n***Key Buffer Size***: Index blocks for MYISAM tables are buffered and are shared by all threads. key_buffer_size is the size of the buffer used for index blocks.\\\n***Adaptive Hash Index Size***: When InnoDB notices that some index values are being accessed very frequently, it builds a hash index for them in memory on top of B-Tree indexes.\\\n ***Query Cache Size***: The query cache stores the text of a SELECT statement together with the corresponding result that was sent to the client. The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time.\\\n***InnoDB Dictionary Size***: The data dictionary is InnoDB \u2018s internal catalog of tables. InnoDB stores the data dictionary on disk, and loads entries into memory while the server is running.\\\n***InnoDB Log Buffer Size***: The MySQL InnoDB log buffer allows transactions to run without having to write the log to disk before the transactions commit.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":52},"hiddenSeries":false,"id":50,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":true,"hideZero":true,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Detailed descriptions about metrics","url":"https:\/\/www.percona.com\/doc\/percona-monitoring-and-management\/dashboard.mysql-overview.html#mysql-internal-memory-overview"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"System Memory","fill":0,"stack":false}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"expr":"node_memory_MemTotal{instance=~\"$host\"}","format":"time_series","intervalFactor":2,"legendFormat":"System Memory","refId":"G","step":4},{"expr":"mysql_global_status_innodb_page_size{instance=~\"$host\"} * on (instance) mysql_global_status_buffer_pool_pages{instance=~\"$host\",state=\"data\"}","format":"time_series","hide":false,"interval":"$interval","intervalFactor":1,"legendFormat":"InnoDB Buffer Pool Data","refId":"A","step":20},{"expr":"mysql_global_variables_innodb_log_buffer_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"InnoDB Log Buffer Size","refId":"D","step":20},{"expr":"mysql_global_variables_innodb_additional_mem_pool_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":2,"legendFormat":"InnoDB Additional Memory Pool Size","refId":"H","step":40},{"expr":"mysql_global_status_innodb_mem_dictionary{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"InnoDB Dictionary Size","refId":"F","step":20},{"expr":"mysql_global_variables_key_buffer_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Key Buffer Size","refId":"B","step":20},{"expr":"mysql_global_variables_query_cache_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Query Cache Size","refId":"C","step":20},{"expr":"mysql_global_status_innodb_mem_adaptive_hash{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Adaptive Hash Index Size","refId":"E","step":20},{"expr":"mysql_global_variables_tokudb_cache_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"TokuDB Cache Size","refId":"I","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Internal Memory Overview","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"bytes","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":null,"min":null,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":59},"id":390,"panels":[],"repeat":null,"title":"Command, Handlers, Processes","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**Top Command Counters**\n\nThe Com_{{xxx}} statement counter variables indicate the number of times each xxx statement has been executed. There is one status variable for each type of statement. For example, Com_delete and Com_update count [``DELETE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/delete.html) and [``UPDATE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/update.html) statements, respectively. Com_delete_multi and Com_update_multi are similar but apply to [``DELETE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/delete.html) and [``UPDATE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/update.html) statements that use multiple-table syntax.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":60},"hiddenSeries":false,"id":14,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":false,"hideZero":false,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Server Status Variables (Com_xxx)","url":"https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/server-status-variables.html#statvar_Com_xxx"}],"nullPointMode":"null as zero","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"topk(5, rate(mysql_global_status_commands_total{instance=~\"$host\"}[$interval])>0) or irate(mysql_global_status_commands_total{instance=~\"$host\"}[5m])>0","format":"time_series","hide":false,"interval":"$interval","intervalFactor":1,"legendFormat":"Com_{{ command }}","metric":"","refId":"B","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Top Command Counters","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":true,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**Top Command Counters Hourly**\n\nThe Com_{{xxx}} statement counter variables indicate the number of times each xxx statement has been executed. There is one status variable for each type of statement. For example, Com_delete and Com_update count [``DELETE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/delete.html) and [``UPDATE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/update.html) statements, respectively. Com_delete_multi and Com_update_multi are similar but apply to [``DELETE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/delete.html) and [``UPDATE``](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/update.html) statements that use multiple-table syntax.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":67},"hiddenSeries":false,"id":39,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[{"title":"Server Status Variables (Com_xxx)","url":"https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/server-status-variables.html#statvar_Com_xxx"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"topk(5, increase(mysql_global_status_commands_total{instance=~\"$host\"}[1h])>0)","format":"time_series","interval":"1h","intervalFactor":1,"legendFormat":"Com_{{ command }}","metric":"","refId":"A","step":3600}],"thresholds":[],"timeFrom":"24h","timeRegions":[],"timeShift":null,"title":"Top Command Counters Hourly","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Handlers**\n\nHandler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.\n\nThis is in fact the layer between the Storage Engine and MySQL.\n\n* `read_rnd_next` is incremented when the server performs a full table scan and this is a counter you don't really want to see with a high value.\n* `read_key` is incremented when a read is done with an index.\n* `read_next` is incremented when the storage engine is asked to 'read the next index entry'. A high value means a lot of index scans are being done.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":74},"hiddenSeries":false,"id":8,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_handlers_total{instance=~\"$host\", handler!~\"commit|rollback|savepoint.*|prepare\"}[$interval]) or irate(mysql_global_status_handlers_total{instance=~\"$host\", handler!~\"commit|rollback|savepoint.*|prepare\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ handler }}","metric":"","refId":"J","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Handlers","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":81},"hiddenSeries":false,"id":28,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_handlers_total{instance=~\"$host\", handler=~\"commit|rollback|savepoint.*|prepare\"}[$interval]) or irate(mysql_global_status_handlers_total{instance=~\"$host\", handler=~\"commit|rollback|savepoint.*|prepare\"}[5m])","interval":"$interval","intervalFactor":1,"legendFormat":"{{ handler }}","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Transaction Handlers","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":0,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":88},"hiddenSeries":false,"id":40,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":false,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null as zero","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_info_schema_threads{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ state }}","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Process States","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":true,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":95},"hiddenSeries":false,"id":49,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":true,"max":true,"min":false,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"topk(5, avg_over_time(mysql_info_schema_threads{instance=~\"$host\"}[1h]))","interval":"1h","intervalFactor":1,"legendFormat":"{{ state }}","metric":"","refId":"A","step":3600}],"thresholds":[],"timeFrom":"24h","timeRegions":[],"timeShift":null,"title":"Top Process States Hourly","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":102},"id":391,"panels":[],"repeat":null,"title":"Query Cache","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Query Cache Memory**\n\nThe query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT\/UPDATE\/DELETE.\n\nThis also means that the larger the `query_cache_size` is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.\n\nThe recommended settings for most environments is to set:\n  ``query_cache_type=0``\n  ``query_cache_size=0``\n\nNote that while you can dynamically change these values, to completely remove the contention point you have to restart the database.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":103},"hiddenSeries":false,"id":46,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_qcache_free_memory{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Free Memory","metric":"","refId":"F","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_query_cache_size{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Query Cache Size","metric":"","refId":"E","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Query Cache Memory","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"bytes","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Query Cache Activity**\n\nThe query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT\/UPDATE\/DELETE.\n\nThis also means that the larger the `query_cache_size` is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.\n\nThe recommended settings for most environments is to set:\n``query_cache_type=0``\n``query_cache_size=0``\n\nNote that while you can dynamically change these values, to completely remove the contention point you have to restart the database.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":103},"height":"","hiddenSeries":false,"id":45,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_qcache_hits{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_qcache_hits{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Hits","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_qcache_inserts{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_qcache_inserts{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Inserts","metric":"","refId":"C","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_qcache_not_cached{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_qcache_not_cached{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Not Cached","metric":"","refId":"D","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_qcache_lowmem_prunes{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_qcache_lowmem_prunes{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Prunes","metric":"","refId":"F","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_qcache_queries_in_cache{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Queries in Cache","metric":"","refId":"E","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Query Cache Activity","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":110},"id":392,"panels":[],"repeat":null,"title":"Files and Tables","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":111},"hiddenSeries":false,"id":43,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_opened_files{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_opened_files{instance=~\"$host\"}[5m])","interval":"$interval","intervalFactor":1,"legendFormat":"Openings","metric":"","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL File Openings","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":111},"hiddenSeries":false,"id":41,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_open_files{instance=~\"$host\"}","interval":"$interval","intervalFactor":1,"legendFormat":"Open Files","metric":"","refId":"A","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_open_files_limit{instance=~\"$host\"}","interval":"$interval","intervalFactor":1,"legendFormat":"Open Files Limit","metric":"","refId":"D","step":20},{"expr":"mysql_global_status_innodb_num_open_files{instance=~\"$host\"}","interval":"$interval","intervalFactor":1,"legendFormat":"InnoDB Open Files","refId":"B","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Open Files","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":118},"id":393,"panels":[],"repeat":null,"title":"Table Openings","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Table Open Cache Status**\n\nThe recommendation is to set the `table_open_cache_instances` to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.\n\nThe `table_definition_cache` and `table_open_cache` can be left as default as they are auto-sized MySQL 5.6 and above (ie: do not set them to any value).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":119},"hiddenSeries":false,"id":44,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Server Status Variables (table_open_cache)","url":"http:\/\/dev.mysql.com\/doc\/refman\/5.6\/en\/server-system-variables.html#sysvar_table_open_cache"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Table Open Cache Hit Ratio","yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"rate(mysql_global_status_opened_tables{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_opened_tables{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Openings","metric":"","refId":"A","step":20},{"expr":"rate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Hits","refId":"B","step":20},{"expr":"rate(mysql_global_status_table_open_cache_misses{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_misses{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Misses","refId":"C","step":20},{"expr":"rate(mysql_global_status_table_open_cache_overflows{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_overflows{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Misses due to Overflows","refId":"D","step":20},{"expr":"(rate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[5m]))\/((rate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_hits{instance=~\"$host\"}[5m]))+(rate(mysql_global_status_table_open_cache_misses{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_table_open_cache_misses{instance=~\"$host\"}[5m])))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Table Open Cache Hit Ratio","refId":"E","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Table Open Cache Status","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"percentunit","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Open Tables**\n\nThe recommendation is to set the `table_open_cache_instances` to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.\n\nThe `table_definition_cache` and `table_open_cache` can be left as default as they are auto-sized MySQL 5.6 and above (ie: do not set them to any value).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":119},"hiddenSeries":false,"id":42,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Server Status Variables (table_open_cache)","url":"http:\/\/dev.mysql.com\/doc\/refman\/5.6\/en\/server-system-variables.html#sysvar_table_open_cache"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_open_tables{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Open Tables","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_table_open_cache{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Table Open Cache","metric":"","refId":"C","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Open Tables","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":126},"id":394,"panels":[],"repeat":null,"title":"MySQL Table Definition Cache","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"**MySQL Table Definition Cache**\n\nThe recommendation is to set the `table_open_cache_instances` to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.\n\nThe `table_definition_cache` and `table_open_cache` can be left as default as they are auto-sized MySQL 5.6 and above (ie: do not set them to any value).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":24,"x":0,"y":127},"hiddenSeries":false,"id":54,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[{"title":"Server Status Variables (table_open_cache)","url":"http:\/\/dev.mysql.com\/doc\/refman\/5.6\/en\/server-system-variables.html#sysvar_table_open_cache"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Opened Table Definitions","yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_open_table_definitions{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Open Table Definitions","metric":"","refId":"B","step":20},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_table_definition_cache{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Table Definitions Cache Size","metric":"","refId":"C","step":20},{"expr":"rate(mysql_global_status_opened_table_definitions{instance=~\"$host\"}[$interval]) or irate(mysql_global_status_opened_table_definitions{instance=~\"$host\"}[5m])","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Opened Table Definitions","refId":"A","step":20}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"MySQL Table Definition Cache","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":134},"id":395,"panels":[],"repeat":null,"title":"System Charts","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":135},"hiddenSeries":false,"id":31,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"rate(node_vmstat_pgpgin{instance=~\"$host\"}[$interval]) * 1024 or irate(node_vmstat_pgpgin{instance=~\"$host\"}[5m]) * 1024","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Page In","metric":"","refId":"A","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"rate(node_vmstat_pgpgout{instance=~\"$host\"}[$interval]) * 1024 or irate(node_vmstat_pgpgout{instance=~\"$host\"}[5m]) * 1024","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Page Out","metric":"","refId":"B","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"I\/O Activity","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"Bps","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"bytes","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":null,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":135},"height":"250px","hiddenSeries":false,"id":37,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"max(node_memory_MemTotal{instance=~\"$host\"}) without(job) - \n(max(node_memory_MemFree{instance=~\"$host\"}) without(job) + \nmax(node_memory_Buffers{instance=~\"$host\"}) without(job) + \n(max(node_memory_Cached{instance=~\"$host\",job=~\"rds-enhanced|linux\"}) without (job) or \nmax(node_memory_Cached{instance=~\"$host\",job=\"rds-basic\"}) without (job)))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Used","metric":"","refId":"A","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"node_memory_MemFree{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Free","metric":"","refId":"B","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"node_memory_Buffers{instance=~\"$host\"}","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Buffers","metric":"","refId":"D","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"max(node_memory_Cached{instance=~\"$host\",job=~\"rds-enhanced|linux\"}) without (job) or \nmax(node_memory_Cached{instance=~\"$host\",job=~\"rds-basic\"}) without (job)","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Cached","metric":"","refId":"E","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Memory Distribution","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"bytes","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"bytes","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{"Load 1m":"#58140C","Max Core Utilization":"#bf1b00","iowait":"#e24d42","nice":"#1f78c1","softirq":"#806eb7","system":"#eab839","user":"#508642"},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":null,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":142},"height":"","hiddenSeries":false,"id":2,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":true,"hideZero":true,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Max Core Utilization","lines":false,"pointradius":1,"points":true,"stack":false},{"alias":"Load 1m","color":"#58140C","fill":2,"legend":false,"stack":false,"yaxis":2}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"clamp_max(((avg by (mode) ( (clamp_max(rate(node_cpu{instance=~\"$host\",mode!=\"idle\"}[$interval]),1)) or (clamp_max(irate(node_cpu{instance=~\"$host\",mode!=\"idle\"}[5m]),1)) ))*100 or (avg_over_time(node_cpu_average{instance=~\"$host\", mode!=\"total\", mode!=\"idle\"}[$interval]) or avg_over_time(node_cpu_average{instance=~\"$host\", mode!=\"total\", mode!=\"idle\"}[5m]))),100)","format":"time_series","hide":false,"interval":"$interval","intervalFactor":1,"legendFormat":"{{ mode }}","metric":"","refId":"A","step":20},{"expr":"clamp_max(max by () (sum  by (cpu) ( (clamp_max(rate(node_cpu{instance=~\"$host\",mode!=\"idle\",mode!=\"iowait\"}[$interval]),1)) or (clamp_max(irate(node_cpu{instance=~\"$host\",mode!=\"idle\",mode!=\"iowait\"}[5m]),1)) ))*100,100)","format":"time_series","hide":true,"interval":"$interval","intervalFactor":1,"legendFormat":"Max Core Utilization","refId":"B","step":20},{"expr":"node_load1{instance=~\"$host\"}","format":"time_series","hide":false,"intervalFactor":2,"legendFormat":"Load 1m","refId":"C"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"CPU Usage \/ Load","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":1,"format":"percent","label":"","logBase":1,"max":100,"min":0,"show":true},{"format":"none","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":142},"height":"250px","hiddenSeries":false,"id":36,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":true,"hideZero":true,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":1,"points":true,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"sum((rate(node_disk_read_time_ms{device!~\"dm-.+\", instance=~\"$host\"}[$interval]) \/ rate(node_disk_reads_completed{device!~\"dm-.+\", instance=~\"$host\"}[$interval])) or (irate(node_disk_read_time_ms{device!~\"dm-.+\", instance=~\"$host\"}[5m]) \/ irate(node_disk_reads_completed{device!~\"dm-.+\", instance=~\"$host\"}[5m]))\nor avg_over_time(aws_rds_read_latency_average{instance=~\"$host\"}[$interval]) or avg_over_time(aws_rds_read_latency_average{instance=~\"$host\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Read","metric":"","refId":"A","step":20,"target":""},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"sum((rate(node_disk_write_time_ms{device!~\"dm-.+\", instance=~\"$host\"}[$interval]) \/ rate(node_disk_writes_completed{device!~\"dm-.+\", instance=~\"$host\"}[$interval])) or (irate(node_disk_write_time_ms{device!~\"dm-.+\", instance=~\"$host\"}[5m]) \/ irate(node_disk_writes_completed{device!~\"dm-.+\", instance=~\"$host\"}[5m])) or \navg_over_time(aws_rds_write_latency_average{instance=~\"$host\"}[$interval]) or avg_over_time(aws_rds_write_latency_average{instance=~\"$host\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Write","metric":"","refId":"B","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Disk Latency","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"ms","label":"","logBase":2,"max":null,"min":null,"show":true},{"format":"ms","label":"","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":null,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":0,"y":149},"height":"250px","hiddenSeries":false,"id":21,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Outbound","transform":"negative-Y"}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"sum(rate(node_network_receive_bytes{instance=~\"$host\", device!=\"lo\"}[$interval])) or sum(irate(node_network_receive_bytes{instance=~\"$host\", device!=\"lo\"}[5m])) or sum(max_over_time(rdsosmetrics_network_rx{instance=~\"$host\"}[$interval])) or sum(max_over_time(rdsosmetrics_network_rx{instance=~\"$host\"}[5m])) ","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Inbound","metric":"","refId":"B","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"sum(rate(node_network_transmit_bytes{instance=~\"$host\", device!=\"lo\"}[$interval])) or sum(irate(node_network_transmit_bytes{instance=~\"$host\", device!=\"lo\"}[5m])) or\nsum(max_over_time(rdsosmetrics_network_tx{instance=~\"$host\"}[$interval])) or sum(max_over_time(rdsosmetrics_network_tx{instance=~\"$host\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Outbound","metric":"","refId":"A","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Network Traffic","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"Bps","label":"Outbound (-) \/ Inbound (+)","logBase":1,"max":null,"min":null,"show":true},{"format":"bytes","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":null,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":7,"w":12,"x":12,"y":149},"hiddenSeries":false,"id":38,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideEmpty":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"rate(node_vmstat_pswpin{instance=~\"$host\"}[$interval]) * 4096 or irate(node_vmstat_pswpin{instance=~\"$host\"}[5m]) * 4096","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Swap In (Reads)","metric":"","refId":"A","step":20,"target":""},{"calculatedInterval":"2s","datasourceErrors":{},"errors":{},"expr":"rate(node_vmstat_pswpout{instance=~\"$host\"}[$interval]) * 4096 or irate(node_vmstat_pswpout{instance=~\"$host\"}[5m]) * 4096","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Swap Out (Writes)","metric":"","refId":"B","step":20,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Swap Activity","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"Bps","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"bytes","logBase":1,"max":null,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}}],"refresh":"5s","schemaVersion":27,"style":"dark","tags":["Percona","MySQL"],"templating":{"list":[{"allFormat":"glob","auto":true,"auto_count":200,"auto_min":"1s","current":{"selected":false,"text":"auto","value":"$__auto_interval_interval"},"datasource":"Prometheus","description":null,"error":null,"hide":0,"includeAll":false,"label":"Interval","multi":false,"multiFormat":"glob","name":"interval","options":[{"selected":true,"text":"auto","value":"$__auto_interval_interval"},{"selected":false,"text":"1s","value":"1s"},{"selected":false,"text":"5s","value":"5s"},{"selected":false,"text":"1m","value":"1m"},{"selected":false,"text":"5m","value":"5m"},{"selected":false,"text":"1h","value":"1h"},{"selected":false,"text":"6h","value":"6h"},{"selected":false,"text":"1d","value":"1d"}],"query":"1s,5s,1m,5m,1h,6h,1d","refresh":2,"skipUrlSync":false,"type":"interval"},{"allFormat":"glob","allValue":null,"current":{"isNone":true,"selected":false,"text":"None","value":""},"datasource":"DS_PROMETHEUS","definition":"","description":null,"error":null,"hide":0,"includeAll":false,"label":"Host","multi":false,"multiFormat":"regex values","name":"host","options":[],"query":{"query":"label_values(mysql_up, instance)","refId":"DS_PROMETHEUS-host-Variable-Query"},"refresh":2,"refresh_on_load":false,"regex":"","skipUrlSync":false,"sort":1,"tagValuesQuery":null,"tags":[],"tagsQuery":null,"type":"query","useTags":false}]},"time":{"from":"now-5m","to":"now"},"timepicker":{"collapse":false,"enable":true,"hidden":false,"notice":false,"now":true,"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"],"status":"Stable","time_options":["5m","15m","1h","6h","12h","24h","2d","7d","30d"],"type":"timepicker"},"timezone":"browser","title":"MySQL Overview","uid":"MQWgroiiz","version":1}
  pxc_galera_node_dashboard.json: |-
    {"annotations":{"list":[{"$$hashKey":"object:627","datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments","hide":true,"iconColor":"rgba(255, 96, 96, 1)","limit":100,"name":"LitmusChaos","showIn":0,"step":"1s","tagKeys":"pod-network-chaos","tags":[],"textFormat":"pod-network-chaos","titleFormat":"chaos","type":"tags","useValueForTime":false},{"$$hashKey":"object:448","builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":false,"iconColor":"#e0752d","limit":100,"matchAny":true,"name":"PMM Annotations","showIn":0,"tags":["pmm_annotation","$node_name","$service_name"],"type":"tags"},{"$$hashKey":"object:449","builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":true,"iconColor":"#6ed0e0","limit":100,"name":"Annotations & Alerts","showIn":0,"tags":[],"type":"dashboard"}]},"editable":true,"gnetId":null,"graphTooltip":1,"id":4,"iteration":1615978059641,"links":[{"icon":"doc","includeVars":true,"keepTime":true,"tags":["Home"],"targetBlank":false,"title":"Home","type":"link","url":"\/graph\/d\/pmm-home\/home-dashboard"},{"icon":"dashboard","includeVars":true,"keepTime":true,"tags":["Query Analytics"],"targetBlank":false,"title":"Query Analytics","type":"link","url":"\/graph\/d\/pmm-qan\/pmm-query-analytics"},{"icon":"bolt","includeVars":true,"keepTime":true,"tags":["Compare"],"targetBlank":false,"title":"Compare","type":"link","url":"\/graph\/d\/pxc-nodes-compare\/pxc-galera-nodes-compare"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["MySQL"],"targetBlank":false,"title":"MySQL","type":"dashboards"},{"asDropdown":true,"includeVars":true,"keepTime":true,"tags":["MySQL_HA"],"targetBlank":false,"title":"HA","type":"dashboards"},{"asDropdown":true,"includeVars":false,"keepTime":true,"tags":["Services"],"targetBlank":false,"title":"Services","type":"dashboards"},{"asDropdown":true,"includeVars":false,"keepTime":true,"tags":["PMM"],"targetBlank":false,"title":"PMM","type":"dashboards"}],"panels":[{"breadcrumbItemsMaxAmount":6,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"gridPos":{"h":2,"w":24,"x":0,"y":0},"hideTextInRootDashboard":false,"id":999,"isRootDashboard":false,"links":[],"targets":[{"expr":"","format":"time_series","intervalFactor":1,"refId":"A"}],"timeFrom":null,"timeShift":null,"title":" ","transparent":true,"type":"digiapulssi-breadcrumb-panel"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["#FA6400","rgba(237, 129, 40, 0.89)","rgba(255, 255, 255, 0.97)"],"datasource":"DS_PROMETHEUS","decimals":0,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"none","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":0,"y":2},"height":"125px","hideTimeOverride":true,"id":50,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_wsrep_ready{service_name=~\"$service_name\"}","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"0.5,1","timeFrom":"1m","timeShift":"1m","title":"Ready to Accept Queries","type":"singlestat","valueFontSize":"50%","valueMaps":[{"op":"=","text":"ON","value":"1"},{"op":"=","text":"OFF","value":"0"}],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["rgba(245, 54, 54, 0.9)","rgba(237, 129, 40, 0.89)","rgba(50, 172, 45, 0.97)"],"datasource":"DS_PROMETHEUS","decimals":0,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"none","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":4,"y":2},"height":"125px","hideTimeOverride":true,"id":49,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_wsrep_local_state{service_name=~\"$service_name\"}","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"2,4","timeFrom":"1m","timeShift":"1m","title":"Local State","type":"singlestat","valueFontSize":"50%","valueMaps":[{"op":"=","text":"Joining","value":"1"},{"op":"=","text":"Donor\/Desynced","value":"2"},{"op":"=","text":"Joined","value":"3"},{"op":"=","text":"Synced","value":"4"}],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["#FA6400","rgba(237, 129, 40, 0.89)","rgba(255, 255, 255, 0.9)"],"datasource":"DS_PROMETHEUS","decimals":0,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"none","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":8,"y":2},"height":"125px","hideTimeOverride":true,"id":53,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_variables_wsrep_desync{service_name=~\"$service_name\"}","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"0.5,1","timeFrom":"1m","timeShift":"1m","title":"Desync Mode","type":"singlestat","valueFontSize":"50%","valueMaps":[{"op":"=","text":"ON","value":"1"},{"op":"=","text":"OFF","value":"0"}],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["rgba(245, 54, 54, 0.9)","rgba(237, 129, 40, 0.89)","rgba(50, 172, 45, 0.97)"],"datasource":"DS_PROMETHEUS","decimals":0,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"none","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":12,"y":2},"height":"125px","hideTimeOverride":true,"id":51,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"mysql_global_status_wsrep_cluster_status{service_name=~\"$service_name\"}","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"0.5,1","timeFrom":"1m","timeShift":"1m","title":"Cluster Status","type":"singlestat","valueFontSize":"50%","valueMaps":[{"op":"=","text":"Primary","value":"1"},{"op":"=","text":"Non-primary","value":"0"}],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":false,"colors":["rgba(50, 172, 45, 0.97)","rgba(237, 129, 40, 0.89)","rgba(245, 54, 54, 0.9)"],"datasource":"DS_PROMETHEUS","decimals":0,"editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"bytes","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":16,"y":2},"height":"125px","id":48,"interval":"$interval","links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"80%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"calculatedInterval":"10m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (mysql_galera_gcache_size_bytes{service_name=~\"$service_name\"})","format":"time_series","interval":"5m","intervalFactor":1,"legendFormat":"","metric":"","refId":"A","step":300}],"thresholds":"90,95","title":"gcache Size","type":"singlestat","valueFontSize":"50%","valueMaps":[],"valueName":"current"},{"cacheTimeout":null,"colorBackground":false,"colorValue":true,"colors":["#FA6400","#508642","rgb(255, 255, 255)"],"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"custom":{}},"overrides":[]},"format":"short","gauge":{"maxValue":100,"minValue":0,"show":false,"thresholdLabels":false,"thresholdMarkers":true},"gridPos":{"h":2,"w":4,"x":20,"y":2},"id":55,"interval":null,"links":[],"mappingType":1,"mappingTypes":[{"name":"value to text","value":1},{"name":"range to text","value":2}],"maxDataPoints":100,"maxPerRow":6,"nullPointMode":"connected","nullText":null,"postfix":"","postfixFontSize":"50%","prefix":"","prefixFontSize":"50%","rangeMaps":[{"from":"null","text":"N\/A","to":"null"}],"sparkline":{"fillColor":"rgba(31, 118, 189, 0.18)","full":false,"lineColor":"rgb(31, 120, 193)","show":true},"tableColumn":"","targets":[{"expr":"avg by (service_name) (mysql_global_status_wsrep_flow_control_status{service_name=~\"$service_name\"})","format":"time_series","interval":"$interval","intervalFactor":1,"refId":"A"}],"thresholds":"0.5,1","title":"FC (normal traffic)","type":"singlestat","valueFontSize":"50%","valueMaps":[{"op":"=","text":"OFF","value":"0"},{"op":"=","text":"ON","value":"1"},{"op":"=","text":"N\/A","value":"null"}],"valueName":"current"},{"aliasColors":{"Maximum":"#806eb7","Standard Deviation":"#7eb26d"},"bars":true,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows figures for the replication latency on group communication. It measures latency from the time point when a message is sent out to the time point when a message is received. As replication is a group operation, this essentially gives you the slowest ACK and longest RTT in the cluster.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":24,"x":0,"y":4},"hiddenSeries":false,"id":42,"legend":{"alignAsTable":true,"avg":true,"current":false,"hideZero":false,"max":true,"min":true,"rightSide":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[{"title":"Galera Documentation","url":"http:\/\/galeracluster.com\/documentation-webpages\/galerastatusvariables.html#wsrep-evs-repl-latency"}],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"avg by (service_name,aggregator) (max_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Maximum\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Maximum\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ aggregator }}","refId":"A","step":300},{"expr":"avg by (service_name,aggregator) (avg_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Standard Deviation\"}[$interval]) or\navg_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Standard Deviation\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ aggregator }}","refId":"B","step":300},{"expr":"avg by (service_name,aggregator) (avg_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Average\"}[$interval]) or\navg_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Average\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ aggregator }}","refId":"C","step":300},{"expr":"avg by (service_name,aggregator) (min_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Minimum\"}[$interval]) or\nmin_over_time(mysql_global_status_wsrep_evs_repl_latency{service_name=~\"$service_name\", aggregator=\"Minimum\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"{{ aggregator }}","refId":"D","step":300}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Replication Latency","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"s","label":"","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":"","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the length of receive and send queues.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":0,"y":12},"hiddenSeries":false,"id":39,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_local_recv_queue{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_local_recv_queue{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Receive Queue","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_local_send_queue{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_local_send_queue{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Send Queue","metric":"","refId":"B","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Replication Queues","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":3,"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":0,"description":"Shows the number of members currently connected to the cluster.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":12,"y":12},"hiddenSeries":false,"id":54,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_cluster_size{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_cluster_size{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Size","metric":"","refId":"C","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Cluster Size","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":0,"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the number of FC_PAUSE events sent\/received. They are sent by a node when its replication queue gets too full. If a node is sending out FC messages it indicates a problem.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":0,"y":20},"hiddenSeries":false,"id":45,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Paused due to Flow Control","linewidth":1,"yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_flow_control_recv{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_flow_control_recv{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"FC Messages Received","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_flow_control_sent{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_flow_control_sent{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"FC Messages Sent","metric":"","refId":"B","step":300,"target":""},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) ((rate(mysql_global_status_wsrep_flow_control_paused_ns{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_flow_control_paused_ns{service_name=~\"$service_name\"}[5m])))\/1000000000","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Paused due to Flow Control","metric":"","refId":"C","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Flow Control","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"short","logBase":1,"max":null,"min":0,"show":true},{"decimals":2,"format":"percentunit","logBase":1,"max":1,"min":0,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the average distances between highest and lowest seqno that are concurrently applied, committed and can be possibly applied in parallel (potential degree of parallelization).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":12,"y":20},"hiddenSeries":false,"id":40,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_apply_window{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_apply_window{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Apply Window","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_commit_window{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_commit_window{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Commit Window","metric":"","refId":"B","step":300,"target":""},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (max_over_time(mysql_global_status_wsrep_cert_deps_distance{service_name=~\"$service_name\"}[$interval]) or\nmax_over_time(mysql_global_status_wsrep_cert_deps_distance{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Cert Deps Distance","metric":"","refId":"C","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Parallelization Efficiency","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the number of local transactions being committed on this node that failed certification (some other node had a commit that conflicted with ours) \u2013 client received deadlock error on commit and also the number of local transactions in flight on this node that were aborted because they locked something an applier thread needed \u2013 deadlock error anywhere in an open transaction. Spikes in the graph may indicate writing to the same table potentially the same rows from 2 nodes.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":0,"y":28},"hiddenSeries":false,"id":41,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_local_cert_failures{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_local_cert_failures{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Local Cert Failures","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_local_bf_aborts{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_local_bf_aborts{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Local Bf Aborts","metric":"","refId":"B","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Writing Conflicts","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"ops","logBase":1,"max":null,"min":0,"show":true},{"format":"ops","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows for how long the node can be taken out of the cluster before SST is required. SST is a full state transfer method.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":12,"y":28},"hiddenSeries":false,"id":47,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"alias":"Time (Instant)","color":"#447ebc","lines":false,"pointradius":1,"points":true}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (mysql_galera_gcache_size_bytes{service_name=~\"$service_name\"}) \/\nignoring(job) (avg by (service_name) (rate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[1h])+rate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[1h])))","format":"time_series","interval":"1h","intervalFactor":1,"legendFormat":"Time (1h avg)","metric":"","refId":"A","step":300},{"expr":"avg by (service_name) (mysql_galera_gcache_size_bytes{service_name=~\"$service_name\"}) \/\nignoring(job) (avg by (service_name) ((rate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[5m])) + \n(rate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[5m]))))","format":"time_series","hide":false,"interval":"$interval","intervalFactor":1,"legendFormat":"Time (Instant)","refId":"B"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Available Downtime before SST Required","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"s","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the count of transactions received from the cluster (any other node) and replicated to the cluster (from this node).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":0,"y":36},"hiddenSeries":false,"id":2,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_received{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_received{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Transactions Received","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_replicated{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_replicated{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Transactions Replicated","metric":"","refId":"B","step":300,"target":""}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Writeset Count","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"cumulative"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"short","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the average transaction size received\/replicated.","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":2,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":12,"y":36},"hiddenSeries":false,"id":11,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[$interval]) \/ rate(mysql_global_status_wsrep_received{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[5m]) \/ irate(mysql_global_status_wsrep_received{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Incoming Transaction Size","metric":"","refId":"C","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[$interval]) \/ rate(mysql_global_status_wsrep_replicated{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[5m]) \/ irate(mysql_global_status_wsrep_replicated{service_name=~\"$service_name\"}[5m]))","interval":"$interval","intervalFactor":1,"legendFormat":"Replicating Transaction Size","metric":"","refId":"A","step":300}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Writeset Size","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"bytes","logBase":1,"max":null,"min":0,"show":true},{"format":"short","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":0,"y":44},"hiddenSeries":false,"id":9,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"sort":"avg","sortDesc":true,"total":false,"values":true},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Inbound","metric":"","refId":"A","step":300},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (rate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[$interval]) or irate(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[5m]))","format":"time_series","interval":"$interval","intervalFactor":1,"legendFormat":"Outbound","metric":"","refId":"B","step":300}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Galera Writeset Traffic","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"bytes","logBase":1,"max":null,"min":0,"show":true},{"format":"none","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":true,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","decimals":2,"description":"Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).","editable":true,"error":false,"fieldConfig":{"defaults":{"custom":{},"links":[]},"overrides":[]},"fill":6,"fillGradient":0,"grid":{},"gridPos":{"h":8,"w":12,"x":12,"y":44},"hiddenSeries":false,"id":38,"legend":{"alignAsTable":true,"avg":true,"current":false,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":false,"linewidth":2,"links":[],"nullPointMode":"null","percentage":false,"pluginVersion":"7.4.3","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (increase(mysql_global_status_wsrep_received_bytes{service_name=~\"$service_name\"}[1h]))","interval":"1h","intervalFactor":1,"legendFormat":"Received","metric":"","refId":"A","step":3600},{"calculatedInterval":"2m","datasourceErrors":{},"errors":{},"expr":"avg by (service_name) (increase(mysql_global_status_wsrep_replicated_bytes{service_name=~\"$service_name\"}[1h]))","interval":"1h","intervalFactor":1,"legendFormat":"Replicated","metric":"","refId":"B","step":3600}],"thresholds":[],"timeFrom":"24h","timeRegions":[],"timeShift":null,"title":"Galera Network Usage Hourly","tooltip":{"msResolution":false,"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"decimals":2,"format":"bytes","logBase":1,"max":null,"min":0,"show":true},{"format":"none","logBase":1,"max":null,"min":0,"show":false}],"yaxis":{"align":false,"alignLevel":null}}],"refresh":"5s","schemaVersion":27,"style":"dark","tags":[],"templating":{"list":[{"allFormat":"glob","auto":true,"auto_count":200,"auto_min":"1s","current":{"selected":false,"text":"auto","value":"$__auto_interval_interval"},"datasource":"Prometheus","description":null,"error":null,"hide":0,"includeAll":false,"label":"Interval","multi":false,"multiFormat":"glob","name":"interval","options":[{"selected":true,"text":"auto","value":"$__auto_interval_interval"},{"selected":false,"text":"1s","value":"1s"},{"selected":false,"text":"5s","value":"5s"},{"selected":false,"text":"1m","value":"1m"},{"selected":false,"text":"5m","value":"5m"},{"selected":false,"text":"1h","value":"1h"},{"selected":false,"text":"6h","value":"6h"},{"selected":false,"text":"1d","value":"1d"}],"query":"1s,5s,1m,5m,1h,6h,1d","refresh":2,"skipUrlSync":false,"type":"interval"},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values(mysql_global_status_wsrep_local_state, node_name)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Node","multi":true,"name":"node_name","options":[],"query":{"query":"label_values(mysql_global_status_wsrep_local_state, node_name)","refId":"DS_PROMETHEUS-node_name-Variable-Query"},"refresh":2,"regex":"","skipUrlSync":false,"sort":1,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allFormat":"glob","allValue":".*","current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values(mysql_galera_variables_info, wsrep_cluster_name)","description":null,"error":null,"hide":0,"includeAll":true,"label":"Cluster","multi":true,"multiFormat":"regex values","name":"cluster","options":[],"query":{"query":"label_values(mysql_galera_variables_info, wsrep_cluster_name)","refId":"DS_PROMETHEUS-cluster-Variable-Query"},"refresh":2,"refresh_on_load":false,"regex":"","skipUrlSync":false,"sort":1,"tagValuesQuery":null,"tags":[],"tagsQuery":null,"type":"query","useTags":false},{"allFormat":"glob","allValue":null,"current":{"isNone":true,"selected":false,"text":"None","value":""},"datasource":"DS_PROMETHEUS","definition":"query_result(mysql_galera_variables_info{wsrep_cluster_name=~\"$cluster\"} * on(service_name) mysql_global_variables_wsrep_rsu_commit_timeout)","description":null,"error":null,"hide":0,"includeAll":false,"label":"Service Name","multi":false,"multiFormat":"regex values","name":"service_name","options":[],"query":{"query":"query_result(mysql_galera_variables_info{wsrep_cluster_name=~\"$cluster\"} * on(service_name) mysql_global_variables_wsrep_rsu_commit_timeout)","refId":"DS_PROMETHEUS-service_name-Variable-Query"},"refresh":2,"refresh_on_load":false,"regex":"\/\"([^\"]+)\"\/","skipUrlSync":false,"sort":1,"tagValuesQuery":null,"tags":[],"tagsQuery":null,"type":"query","useTags":false},{"allValue":".*","current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, environment)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Environment","multi":true,"name":"environment","options":[],"query":{"query":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, environment)","refId":"DS_PROMETHEUS-environment-Variable-Query"},"refresh":2,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, replication_set)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Replication Set","multi":true,"name":"replication_set","options":[],"query":{"query":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, replication_set)","refId":"DS_PROMETHEUS-replication_set-Variable-Query"},"refresh":2,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values(pg_stat_database_tup_fetched{service_name=~\"$service_name\",datname!~\"template.*|postgres\"},datname)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Database","multi":true,"name":"database","options":[],"query":{"query":"label_values(pg_stat_database_tup_fetched{service_name=~\"$service_name\",datname!~\"template.*|postgres\"},datname)","refId":"DS_PROMETHEUS-database-Variable-Query"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, node_type)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Type","multi":true,"name":"node_type","options":[],"query":{"query":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, node_type)","refId":"DS_PROMETHEUS-node_type-Variable-Query"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, service_type)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Type","multi":true,"name":"service_type","options":[],"query":{"query":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, service_type)","refId":"DS_PROMETHEUS-service_type-Variable-Query"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{"selected":false,"text":"All","value":"$__all"},"datasource":"DS_PROMETHEUS","definition":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, schema)","description":null,"error":null,"hide":2,"includeAll":true,"label":"Schema","multi":true,"name":"schema","options":[],"query":{"query":"label_values({__name__=~\"pg_up|mysql_up|mongodb_up|proxysql_mysql_status_active_transactions\"}, schema)","refId":"DS_PROMETHEUS-schema-Variable-Query"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false}]},"time":{"from":"now-30m","to":"now"},"timepicker":{"collapse":false,"enable":true,"hidden":false,"notice":false,"now":true,"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"],"status":"Stable","time_options":["5m","15m","1h","6h","12h","24h","2d","7d","30d"],"type":"timepicker"},"timezone":"browser","title":"PXC\/Galera Node Summary","uid":null,"version":1}
  sock_shop_performance_dashboard.json: |-
    {"annotations":{"list":[{"$$hashKey":"object:258","builtIn":1,"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_awaited_experiments{chaosresult_name=~\"$chaosresult_name\", job=\"litmus/chaos-exporter\", app=\"chaos-exporter\"}","hide":false,"iconColor":"#FF780A","limit":100,"name":"LitmusChaos Events","showIn":0,"step":"1s","tagKeys":"$chaosresult_name","textFormat":"<br/>  <p><b>Chaos Details:- </b><br/> <ul> <li> Verdict: Awaited <li> Result Namespace: {{chaosresult_namespace}} <li> Instance on which Chaos Engine created jobs: {{instance}} </ul> </p>","titleFormat":"Chaos Result: {{chaosresult_name}}","type":"dashboard"},{"datasource":"DS_PROMETHEUS","enable":true,"expr":"litmuschaos_experiment_verdict{chaosresult_name=~\"$chaosresult_name\",chaosengine_context=~\"$chaosengine_context\", job=\"litmus/chaos-exporter\", app=\"chaos-exporter\"}","hide":false,"iconColor":"#A352CC","name":"LitmusChaos Metrics","showIn":0,"step":"1s","tagKeys":"$chaosresult_name","textFormat":"<br/>  <p><b>Chaos Details:- </b><br/> <ul> <li> Verdict: {{chaosresult_verdict}} <li> Probe Success %: {{probe_success_percentage}} </ul> </p> <p><b>App Details:- </b><br/> <ul> <li> Engine Context: {{chaosengine_context}} <li> Label: {{app_label}} <li> Kind: {{app_kind}} <li> Namespace: {{app_namespace}} </ul> </p>","titleFormat":"Chaos Result: {{chaosresult_name}}","useValueForTime":false}]},"editable":true,"gnetId":null,"graphTooltip":0,"id":null,"iteration":1619881847590,"links":[],"panels":[{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":0},"id":20,"panels":[],"repeat":null,"title":"Chaos Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"unit":"none"},"overrides":[]},"fill":10,"fillGradient":5,"gridPos":{"h":9,"w":24,"x":0,"y":1},"hiddenSeries":false,"id":29,"legend":{"alignAsTable":false,"avg":false,"current":false,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":true,"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos Annotations","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transparent":true,"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:517","format":"none","label":"Chaos events and metrics","logBase":2,"max":"1","min":"0","show":true},{"$$hashKey":"object:518","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"unit":"none"},"overrides":[]},"fill":10,"fillGradient":5,"gridPos":{"h":9,"w":12,"x":0,"y":10},"hiddenSeries":false,"id":31,"legend":{"alignAsTable":false,"avg":false,"current":false,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:1382","alias":"/.*Fail/","color":"#E02F44"}],"spaceLength":10,"stack":false,"steppedLine":true,"targets":[{"exemplar":true,"expr":"litmuschaos_awaited_experiments{job=\"litmus/chaos-exporter\"}","hide":false,"interval":"","legendFormat":"{{chaosresult_name}}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos Experiments","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:517","format":"none","label":"Chaos injections","logBase":2,"max":"1","min":"0","show":true},{"$$hashKey":"object:518","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"cacheTimeout":null,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"none"},"overrides":[]},"gridPos":{"h":9,"w":3,"x":12,"y":10},"id":16,"interval":null,"links":[],"maxDataPoints":100,"options":{"orientation":"horizontal","reduceOptions":{"calcs":["max"],"fields":"","values":false},"showThresholdLabels":false,"showThresholdMarkers":true,"text":{}},"pluginVersion":"7.5.5","targets":[{"exemplar":true,"expr":"sum(litmuschaos_passed_experiments{job=\"litmus/chaos-exporter\"} + litmuschaos_failed_experiments{job=\"litmus/chaos-exporter\"})","instant":false,"interval":"","intervalFactor":2,"legendFormat":"","refId":"A","step":20}],"timeFrom":null,"timeShift":null,"title":"Total Experiments Run","type":"gauge"},{"cacheTimeout":null,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"none"},"overrides":[]},"gridPos":{"h":9,"w":3,"x":15,"y":10},"id":28,"interval":null,"links":[],"maxDataPoints":100,"options":{"orientation":"horizontal","reduceOptions":{"calcs":["max"],"fields":"","values":false},"showThresholdLabels":false,"showThresholdMarkers":true,"text":{}},"pluginVersion":"7.5.5","targets":[{"exemplar":true,"expr":"sum(litmuschaos_passed_experiments{job=\"litmus/chaos-exporter\"})","instant":false,"interval":"","intervalFactor":2,"legendFormat":"","refId":"A","step":20}],"timeFrom":null,"timeShift":null,"title":"Passed Experiments","type":"gauge"},{"cacheTimeout":null,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"none"},"overrides":[]},"gridPos":{"h":9,"w":3,"x":18,"y":10},"id":19,"interval":null,"links":[],"maxDataPoints":100,"options":{"orientation":"horizontal","reduceOptions":{"calcs":["max"],"fields":"","values":false},"showThresholdLabels":false,"showThresholdMarkers":true,"text":{}},"pluginVersion":"7.5.5","targets":[{"exemplar":true,"expr":"sum(litmuschaos_failed_experiments{job=\"litmus/chaos-exporter\"})","instant":false,"interval":"","intervalFactor":2,"legendFormat":"","refId":"A","step":20}],"title":"Failed Experiments","type":"gauge"},{"cacheTimeout":null,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"none"},"overrides":[]},"gridPos":{"h":9,"w":3,"x":21,"y":10},"id":18,"interval":null,"links":[],"maxDataPoints":100,"options":{"orientation":"horizontal","reduceOptions":{"calcs":["mean"],"fields":"","values":false},"showThresholdLabels":false,"showThresholdMarkers":true,"text":{}},"pluginVersion":"7.5.5","targets":[{"exemplar":true,"expr":"sum(litmuschaos_awaited_experiments{job=\"litmus/chaos-exporter\"})","instant":true,"interval":"","intervalFactor":10,"legendFormat":"","refId":"A"}],"title":"Queued Experiments","type":"gauge"},{"alert":{"alertRuleTags":{},"conditions":[{"evaluator":{"params":[0.99],"type":"gt"},"operator":{"type":"and"},"query":{"params":["A","5s","now"]},"reducer":{"params":[],"type":"max"},"type":"query"}],"executionErrorState":"alerting","for":"1s","frequency":"1s","handler":1,"message":"Chaos Experiment Failed !!!\n\n<br/> \n<p><b>Chaos Details:- </b><br/>\n<ul>\n<li> Verdict: ${chaosresult_verdict}\n<li> Probe Success %: ${probe_success_percentage}\n</ul>\n</p>\n<p><b>App Details:- </b><br/>\n<ul>\n<li> Engine Context: ${chaosengine_context}\n<li> Label: ${app_label}\n<li> Kind: ${app_kind}\n<li> Namespace: ${app_namespace}\n</ul>\n</p>","name":"Chaos Experiment Failure","noDataState":"no_data","notifications":[]},"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"unit":"none"},"overrides":[]},"fill":10,"fillGradient":5,"gridPos":{"h":9,"w":12,"x":0,"y":19},"hiddenSeries":false,"id":15,"legend":{"alignAsTable":true,"avg":false,"current":false,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:1382","alias":"/.*Fail/","color":"#E02F44"}],"spaceLength":10,"stack":false,"steppedLine":true,"targets":[{"exemplar":true,"expr":"litmuschaos_experiment_verdict{job=\"litmus/chaos-exporter\", app=\"chaos-exporter\", chaosresult_verdict=\"Fail\"}","format":"time_series","hide":false,"instant":false,"interval":"1s","legendFormat":"{{app_label}} - {{chaosresult_name}} - {{chaosresult_verdict}}","refId":"A"}],"thresholds":[{"colorMode":"critical","fill":true,"line":true,"op":"gt","value":0.99,"visible":true}],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos Experiment Verdict Failure Alerts","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transparent":true,"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:517","format":"none","label":"Experiments failed","logBase":2,"max":"1","min":"0","show":true},{"$$hashKey":"object:518","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"alert":{"alertRuleTags":{},"conditions":[{"evaluator":{"params":[0.99],"type":"gt"},"operator":{"type":"and"},"query":{"params":["A","5s","now"]},"reducer":{"params":[],"type":"max"},"type":"query"}],"executionErrorState":"alerting","for":"1s","frequency":"1s","handler":1,"message":"Chaos Probe Failed !!!\n\n<br/> \n<p><b>Chaos Details:- </b><br/>\n<ul>\n<li> Verdict: ${chaosresult_verdict}\n<li> Probe Success %: ${probe_success_percentage}\n</ul>\n</p>\n<p><b>App Details:- </b><br/>\n<ul>\n<li> Engine Context: ${chaosengine_context}\n<li> Label: ${app_label}\n<li> Kind: ${app_kind}\n<li> Namespace: ${app_namespace}\n</ul>\n</p>","name":"Chaos Experiment Probe Failure Alerts alert","noDataState":"no_data","notifications":[]},"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"unit":"none"},"overrides":[]},"fill":10,"fillGradient":5,"gridPos":{"h":9,"w":12,"x":12,"y":19},"hiddenSeries":false,"id":30,"legend":{"alignAsTable":true,"avg":false,"current":false,"hideEmpty":true,"hideZero":true,"max":false,"min":false,"rightSide":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:1382","alias":"/.*Fail/","color":"#E02F44"}],"spaceLength":10,"stack":false,"steppedLine":true,"targets":[{"exemplar":true,"expr":"litmuschaos_experiment_verdict{job=\"litmus/chaos-exporter\", app=\"chaos-exporter\", probe_success_percentage!=\"100.000000\"}","format":"time_series","hide":false,"instant":false,"interval":"1s","legendFormat":"{{app_label}} - {{chaosresult_name}} - {{probe_success_percentage}}","refId":"A"}],"thresholds":[{"colorMode":"critical","fill":true,"line":true,"op":"gt","value":0.99,"visible":true}],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Chaos Experiment Probe Failure Alerts","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transparent":true,"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:517","decimals":null,"format":"none","label":"Probes failed","logBase":2,"max":"1","min":"0","show":true},{"$$hashKey":"object:518","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":28},"id":21,"panels":[],"repeat":null,"title":"Orders Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":29},"hiddenSeries":false,"id":5,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:123","alias":"2xx","lines":true},{"$$hashKey":"object:272","alias":"orders-pod-memory-hog","color":"#C4162A","fillGradient":7,"steppedLine":true,"yaxis":2},{"$$hashKey":"object:282","alias":"orders-node-memory-hog","color":"#C4162A","fillGradient":7,"steppedLine":true,"yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"exemplar":true,"expr":"sum(rate(request_duration_seconds_count{job=\"orders\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":2},{"expr":"sum(rate(request_duration_seconds_count{job=\"orders\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":2},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"orders-pod-memory-hog-pod-memory-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"orders-pod-memory-hog-pod-memory-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"orders-pod-memory-hog","refId":"D"},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"orders-node-memory-hog-node-memory-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"orders-node-memory-hog-node-memory-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"orders-node-memory-hog","refId":"F"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Orders QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:149","format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"$$hashKey":"object:150","decimals":null,"format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":29},"hiddenSeries":false,"id":6,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:115","alias":"99th quantile","lines":true},{"$$hashKey":"object:116","alias":"50th quantile","lines":true},{"$$hashKey":"object:117","alias":"Mean","lines":true},{"$$hashKey":"object:183","alias":"orders-pod-memory-hog","color":"#C4162A","fillGradient":7,"steppedLine":true,"yaxis":2},{"$$hashKey":"object:193","alias":"orders-node-memory-hog","color":"#C4162A","fillGradient":7,"steppedLine":true,"yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"orders\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":2},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"orders\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":2},{"expr":"sum(rate(request_duration_seconds_sum{job=\"orders\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"orders\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":2},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"orders-pod-memory-hog-pod-memory-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"orders-pod-memory-hog-pod-memory-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"orders-pod-memory-hog","refId":"E"},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"orders-node-memory-hog-node-memory-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"orders-node-memory-hog-node-memory-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"orders-node-memory-hog","refId":"G"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Orders latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:155","format":"s","logBase":1,"min":0,"show":true},{"$$hashKey":"object:156","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":36},"id":22,"panels":[],"repeat":null,"title":"Catalogue Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":8,"w":12,"x":0,"y":37},"hiddenSeries":false,"id":1,"legend":{"avg":false,"current":false,"hideEmpty":false,"max":false,"min":false,"rightSide":false,"show":true,"total":false,"values":false},"lines":false,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:414","alias":"2xx","lines":true},{"$$hashKey":"object:415","alias":"catalogue-pod-cpu-hog","color":"#C4162A","fillGradient":7,"lines":true,"steppedLine":true,"yaxis":2},{"$$hashKey":"object:525","alias":"catalogue-node-cpu-hog","color":"#C4162A","fillGradient":7,"lines":true,"steppedLine":true,"yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"catalogue\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":2},{"expr":"sum(rate(request_duration_seconds_count{job=\"catalogue\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":2},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"catalogue-pod-cpu-hog-pod-cpu-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"catalogue-pod-cpu-hog-pod-cpu-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"catalogue-pod-cpu-hog","refId":"C"},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"catalogue-node-cpu-hog-node-cpu-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"catalogue-node-cpu-hog-node-cpu-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"catalogue-node-cpu-hog","refId":"E"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Catalogue QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:442","format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"$$hashKey":"object:443","decimals":null,"format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":8,"w":12,"x":12,"y":37},"hiddenSeries":false,"id":2,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:959","alias":"99th quantile","lines":true},{"$$hashKey":"object:960","alias":"50th quantile","lines":true},{"$$hashKey":"object:961","alias":"Mean","lines":true},{"$$hashKey":"object:962","alias":"catalogue-pod-cpu-hog","color":"#C4162A","fillGradient":7,"lines":true,"steppedLine":true,"yaxis":2},{"$$hashKey":"object:1053","alias":"catalogue-node-cpu-hog","color":"#C4162A","fillGradient":7,"lines":true,"steppedLine":true,"yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"catalogue\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":2},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"catalogue\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":2},{"expr":"sum(rate(request_duration_seconds_sum{job=\"catalogue\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"catalogue\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":2},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"catalogue-pod-cpu-hog-pod-cpu-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"catalogue-pod-cpu-hog-pod-cpu-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"catalogue-pod-cpu-hog","refId":"D"},{"expr":"litmuschaos_experiment_chaos_injected_time{chaosresult_name=\"catalogue-node-cpu-hog-node-cpu-hog\",chaosresult_namespace=\"kubera\"} - on () (litmuschaos_experiment_end_time{chaosresult_name=\"catalogue-node-cpu-hog-node-cpu-hog\",chaosresult_namespace=\"kubera\"} OR on() vector(0))","interval":"","legendFormat":"catalogue-node-cpu-hog","refId":"F"}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Catalogue latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1001","format":"s","logBase":1,"min":0,"show":true},{"$$hashKey":"object:1002","format":"short","label":"CHAOS","logBase":2,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":45},"id":23,"panels":[],"repeat":null,"title":"Payement Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":46},"hiddenSeries":false,"id":7,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"payment\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":2},{"expr":"sum(rate(request_duration_seconds_count{job=\"payment\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":2}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Payment QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1295","format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"$$hashKey":"object:1296","format":"short","logBase":1,"max":null,"min":null,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":46},"hiddenSeries":false,"id":8,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"payment\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":2},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"payment\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":2},{"expr":"sum(rate(request_duration_seconds_sum{job=\"payment\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"payment\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":2}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Payment latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"s","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":53},"id":24,"panels":[],"repeat":null,"title":"Shipping Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":54},"hiddenSeries":false,"id":9,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"shipping\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":10},{"expr":"sum(rate(request_duration_seconds_count{job=\"shipping\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Shipping QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1578","format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"$$hashKey":"object:1579","format":"short","label":"","logBase":1,"max":null,"min":null,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":54},"hiddenSeries":false,"id":10,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"shipping\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":10},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"shipping\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":10},{"expr":"sum(rate(request_duration_seconds_sum{job=\"shipping\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"shipping\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Shipping latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"s","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":61},"id":25,"panels":[],"repeat":null,"title":"User Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":62},"hiddenSeries":false,"id":11,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"user\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":10},{"expr":"sum(rate(request_duration_seconds_count{job=\"user\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"User QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":62},"hiddenSeries":false,"id":12,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"user\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":10},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"user\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":10},{"expr":"sum(rate(request_duration_seconds_sum{job=\"user\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"user\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"User latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"s","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":69},"id":26,"panels":[],"repeat":null,"title":"Frontend Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":70},"hiddenSeries":false,"id":13,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"front-end\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":10},{"expr":"sum(rate(request_duration_seconds_count{job=\"front-end\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Frontend QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":70},"hiddenSeries":false,"id":14,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"front-end\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":10},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"front-end\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":10},{"expr":"sum(rate(request_duration_seconds_sum{job=\"front-end\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"front-end\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Frontend latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"s","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"collapsed":false,"datasource":"DS_PROMETHEUS","gridPos":{"h":1,"w":24,"x":0,"y":77},"id":27,"panels":[],"repeat":null,"title":"Cart Metrics","type":"row"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":0,"y":78},"hiddenSeries":false,"id":3,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(request_duration_seconds_count{job=\"carts\",status_code=~\"2..\",route!=\"metrics\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"2xx","refId":"A","step":10},{"expr":"sum(rate(request_duration_seconds_count{job=\"carts\",status_code=~\"4.+|5.+\"}[1m])) * 100","interval":"","intervalFactor":2,"legendFormat":"4xx/5xx","refId":"B","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Cart QPS","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"ops","label":"QPS (1 min)","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"DS_PROMETHEUS","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":0,"gridPos":{"h":7,"w":12,"x":12,"y":78},"hiddenSeries":false,"id":4,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"7.5.5","pointradius":5,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{job=\"carts\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"99th quantile","refId":"A","step":10},{"expr":"histogram_quantile(0.5, sum(rate(request_duration_seconds_bucket{job=\"carts\"}[1m])) by (name, le))","interval":"","intervalFactor":2,"legendFormat":"50th quantile","refId":"B","step":10},{"expr":"sum(rate(request_duration_seconds_sum{job=\"carts\"}[1m])) / sum(rate(request_duration_seconds_count{job=\"carts\"}[1m]))","interval":"","intervalFactor":2,"legendFormat":"Mean","refId":"C","step":10}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Cart latency","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"s","logBase":1,"min":0,"show":true},{"format":"short","logBase":1,"show":true}],"yaxis":{"align":false,"alignLevel":null}}],"refresh":"10s","schemaVersion":27,"style":"dark","tags":[],"templating":{"list":[{"allValue":null,"current":{},"datasource":"DS_PROMETHEUS","definition":"label_values(litmuschaos_awaited_experiments{app=~\"chaos-exporter\"}, chaosresult_name)","description":"Chaos results","error":null,"hide":0,"includeAll":false,"label":"Chaos Result","multi":true,"name":"chaosresult_name","options":[],"query":{"query":"label_values(litmuschaos_awaited_experiments{app=~\"chaos-exporter\"}, chaosresult_name)","refId":"StandardVariableQuery"},"refresh":2,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false},{"allValue":null,"current":{},"datasource":"DS_PROMETHEUS","definition":"label_values(litmuschaos_experiment_verdict{app=~\"chaos-exporter\"}, chaosengine_context)","description":"Chaos Engine contexts","error":null,"hide":0,"includeAll":false,"label":"Chaos Engine context","multi":true,"name":"chaosengine_context","options":[],"query":{"query":"label_values(litmuschaos_experiment_verdict{app=~\"chaos-exporter\"}, chaosengine_context)","refId":"StandardVariableQuery"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false}]},"time":{"from":"now-30m","to":"now"},"timepicker":{"collapse":false,"enable":true,"hidden":false,"notice":false,"now":true,"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"],"status":"Stable","time_options":["5m","15m","1h","6h","12h","24h","2d","7d","30d"],"type":"timepicker"},"timezone":"browser","title":"Sock-Shop Performance","uid":null,"version":1}
  boutique-app-dashboard.json: |-
    {"annotations":{"list":[{"builtIn":1,"datasource":{"type":"grafana","uid":"-- Grafana --"},"enable":true,"hide":true,"iconColor":"rgba(0, 211, 255, 1)","name":"Annotations & Alerts","target":{"limit":100,"matchAny":false,"tags":[],"type":"dashboard"},"type":"dashboard"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"enable":true,"expr":"litmuschaos_awaited_experiments{job=\"chaos-exporter\"}","iconColor":"red","name":"Chaos Period","step":"1s","target":{"limit":100,"matchAny":false,"tags":[],"type":"dashboard"}}]},"editable":true,"fiscalYearStartMonth":0,"graphTooltip":0,"id":6,"iteration":1658076845411,"links":[],"liveNow":false,"panels":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]}},"overrides":[{"__systemRef":"hideSeriesFrom","matcher":{"id":"byNames","options":{"mode":"exclude","names":["{instance=\"frontend.boutique.svc.cluster.local:80\", job=\"prometheus-blackbox-exporter\"}"],"prefix":"All except:","readOnly":true}},"properties":[{"id":"custom.hideFrom","value":{"legend":false,"tooltip":false,"viz":true}}]}]},"gridPos":{"h":9,"w":24,"x":0,"y":0},"id":2,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_success{instance=\"frontend.boutique.svc.cluster.local:80\", job=\"prometheus-blackbox-exporter\"}[60s:1s])*100","refId":"A"}],"title":"Probe Success Percentage","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"QPS(1 min)","axisPlacement":"left","barAlignment":-1,"drawStyle":"line","fillOpacity":14,"gradientMode":"hue","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineStyle":{"fill":"solid"},"lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"always","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"ops"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":0,"y":9},"id":16,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/\",status_code=~\"2..\"}[1m])) * 100","refId":"A"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/\",status_code=~\"4.+|5.+\"}[1m])) * 100","hide":false,"refId":"B"}],"title":"Frontend QPS","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":9},"id":4,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"frontend.boutique.svc.cluster.local:80\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration (Frontend service)","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"description":"","fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"QPS (1 min)","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineStyle":{"fill":"solid"},"lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"ops"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":0,"y":17},"id":18,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/cart\",status_code=~\"2..\"}[1m])) * 100","refId":"A"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/cart\",status_code=~\"4.+|5.+\"}[1m])) * 100","hide":false,"refId":"B"}],"title":"Cart QPS","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":17},"id":8,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"cartservice.boutique.svc.cluster.local:7070\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration(cartservice)","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"QPS (1 min)","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"ops"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":0,"y":25},"id":20,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/product/{id}\",status_code=~\"2..\"}[1m])) * 100","refId":"A"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/product/{id}\",status_code=~\"4.+|5.+\"}[1m])) * 100","hide":false,"refId":"B"}],"title":"Product QPS","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":25},"id":12,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"productcatalogservice.boutique.svc.cluster.local:3550\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration(ProductCatalogservice)","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"QPS (1 min)","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"ops"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":0,"y":33},"id":22,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/cart/checkout\",status_code=~\"2..\"}[1m])) * 100","refId":"A"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"sum(rate(http_server_request_duration_seconds_count{route=\"/cart/checkout\",status_code=~\"4.+|5.+\"}[1m])) * 100","hide":false,"refId":"B"}],"title":"Checkout Qps","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":33},"id":10,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"checkoutservice.boutique.svc.cluster.local:5050\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration(checkoutservice)","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":41},"id":6,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"adservice.boutique.svc.cluster.local:9555\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration(Adservice)","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":49},"id":24,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"currencyservice.boutique.svc.cluster.local:7000\"}[60s:1s])*1000","refId":"A"}],"title":"Currency Service Latency","type":"timeseries"},{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":8,"gradientMode":"none","hideFrom":{"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"linear","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"auto","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"s"},"overrides":[]},"gridPos":{"h":8,"w":12,"x":12,"y":57},"id":14,"options":{"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single","sort":"none"}},"targets":[{"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"expr":"avg_over_time(probe_duration_seconds{job=\"prometheus-blackbox-exporter\", instance=\"redis-cart.boutique.svc.cluster.local:6379\"}[60s:1s])*1000","refId":"A"}],"title":"Access Duration(redis-cart)","type":"timeseries"}],"refresh":"5s","schemaVersion":36,"style":"dark","tags":[],"templating":{"list":[{"current":{"selected":true,"text":["pod-deletegnr7q-pod-delete","pod-deletec2hjw-pod-delete"],"value":["pod-deletegnr7q-pod-delete","pod-deletec2hjw-pod-delete"]},"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"definition":"label_values(litmuschaos_awaited_experiments{job=~\"chaos-exporter\"}, chaosresult_name)","description":"Chaos results","hide":0,"includeAll":false,"label":"Chaos Result","multi":true,"name":"chaosresult_name","options":[],"query":{"query":"label_values(litmuschaos_awaited_experiments{job=~\"chaos-exporter\"}, chaosresult_name)","refId":"StandardVariableQuery"},"refresh":2,"regex":"","skipUrlSync":false,"sort":0,"type":"query"},{"current":{"selected":true,"text":["pod-delete_ns-3"],"value":["pod-delete_ns-3"]},"datasource":{"type":"prometheus","uid":"PBFE396EC0B189D67"},"definition":"label_values(litmuschaos_experiment_verdict{job=~\"chaos-exporter\"}, chaosengine_context)","description":"Chaos Engine contexts","hide":0,"includeAll":false,"label":"Chaos Engine context","multi":true,"name":"chaosengine_context","options":[],"query":{"query":"label_values(litmuschaos_experiment_verdict{job=~\"chaos-exporter\"}, chaosengine_context)","refId":"StandardVariableQuery"},"refresh":1,"regex":"","skipUrlSync":false,"sort":0,"type":"query"}]},"time":{"from":"now-5m","to":"now"},"timepicker":{},"timezone":"","title":"Boutique App DashBoard","uid":"OmfepNR4z","version":4,"weekStart":""}



---
##Datasource configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: litmus-grafana-datasources
data:
  prometheus.yaml: |-
    {
        "apiVersion": 1,
        "datasources": [
            {
               "access":"proxy",
                "editable": true,
                "name": "DS_PROMETHEUS",
                "orgId": 1,
                "type": "prometheus",
                "url": "http://prometheus-k8s:9090",
                "version": 1
            }
        ]
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
      name: grafana
    spec:
      containers:
        - image: grafana/grafana:latest
          imagePullPolicy: Always
          name: grafana
          ports:
            - containerPort: 3000
              name: grafana
              protocol: TCP
          volumeMounts:
            - mountPath: /etc/grafana/provisioning/datasources
              name: grafana-datasources
            - mountPath: /etc/grafana/provisioning/dashboards
              name: grafana-provisioner
            - mountPath: /var/lib/grafana/dashboards/
              name: grafana-dashboards
            - mountPath: /var/lib/grafana
              name: grafana-storage
      volumes:
        - emptyDir: {}
          name: grafana-storage
        - name: grafana-datasources
          configMap:
            defaultMode: 420
            name: litmus-grafana-datasources
        - name: grafana-dashboards
          configMap:
            defaultMode: 420
            name: litmus-grafana-dashboards
        - name: grafana-provisioner
          configMap:
            defaultMode: 420
            name: litmus-grafana-provisioner
---
apiVersion: v1
kind: Service
metadata:
  annotations:
  name: grafana
spec:
  ports:
    - port: 3000
      protocol: TCP
      targetPort: 3000
      # nodePort: 31688
  selector:
    app: grafana
  sessionAffinity: None
  type: LoadBalancer
